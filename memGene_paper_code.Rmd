---
title: "MEMgene paper analysis"
output: 
  html_document:
    theme: flatly
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
      smooth_scroll: false
---

Analysis of simulated datasets from Lotterhos & Whitlock with the same random sampling of 90 sites as in Wagner et al. (2017).

Goal:

Design:

Genetic data:

Response variables:


## 1. Preparations

### a) Packages

```{r packages}
#library(adegenet)
library(hierfstat)
#library(spdep)
#library(adespatial)
library(memgene)
library(here)
library(parallel)
library(dplyr)
library(spdep)
```

### b) Import patial coordinates

```{r coords}
Coords <- list()
Coords$Pairs <- list()
# Coords$Pairs$E453 <- read.table("1351142954_453EnviMatPAIRS_ED.txt")
# Coords$Pairs$E988 <- read.table("1351142970_988EnviMatPAIRS_ED.txt")
# Coords$Pairs$E950 <- read.table("1351142986_950EnviMatPAIRS_ED.txt")
Coords$Transect <- list()
# Coords$Transect$E453 <- read.table("1351142954_453EnviMatTRANSECTS_ED_Design.txt")
# Coords$Transect$E988 <- read.table("1351142970_988EnviMatTRANSECTS_ED_Design.txt")
# Coords$Transect$E950 <- read.table("1351142986_950EnviMatTRANSECTS_ED_Design.txt")
Coords$Random <- list()
Coords$Random$E453 <- Coords$Random$E988 <- Coords$Random$E950 <- 
  read.table("SchemeRandom1.txt") # upload this file

# for(k in 1:length(Coords$Transect))
# {
#   names(Coords$Transect[[k]])[2:3] <- names(Coords$Pairs[[1]])[2:3]
#   Coords$Transect[[k]][,7:9][is.na(Coords$Transect[[k]][,7:9])] <- FALSE
# }
for(i in 1:length(Coords))
{
  if(length(Coords[[i]]) > 0)
  {
    for(k in 1:length(Coords[[i]]))
    {
      b <- order(Coords[[i]][[k]][,3], Coords[[i]][[k]][,2]) # Sort by y, then x
      Coords[[i]][[k]] <- Coords[[i]][[k]][b,]  # correct order!!
    }
  }
  
}
```

### c) Parameter space

Genetic data: find all file names in the folder "SimFilesLFMM" that contain 'lfmm':

```{r files}
Filenames.lfmm <- list.files(paste0(here::here(), "/dryad//SimFilesLFMM/"), pattern="lfmm") 

test <- Reduce(rbind, strsplit(Filenames.lfmm, split="[_=]"))
test <- cbind(test, Reduce(rbind, strsplit(test[,ncol(test)], split="[.]")))
tmp <- strsplit(test[,2], split="[.xs]")
test2 <- matrix(NA, nrow(test), 3)
for(i in 1:nrow(test)) test2[i,1:length(tmp[[i]])] <- tmp[[i]]
test2 <- gsub("[A-Z, a-z]","", test2)
test <- cbind(test, test2)
dimnames(test) <- list(NULL, c("Demography", "Design", "ID", "Env", "ID2", 
                               "V6", "NumPops", "V8", "V9", "NumInd", "Design2",
                               "NumPops2", "NumTrans", "NumInd2"))
```

Design matrix (parameter space): each row is one combination of parameter settings:

- Demography: single refugium (1R), two refugia (2R), isolation by distane (IBD), island model (IM)
- Design: sampling design (R, P, T; see below) and number of pops sampled
- Env: which of the three replicate landscapes '453', '950', '988'
- NumPops: how many populations are sampled
- NumInd: how many individuals sampled per pop
- Type: random (R), pairs (P), transects (T)

```{r Design}   
   Design <- as.data.frame(test[,c(1,2,4,7,10,13,14)])
   Design$Env <- ordered(Design$Env, levels=c(453,988,950))
   Design$Type <- ordered(substr(Design$Design, 1, 1), levels=c("P", "T", "R"))
   Design$Design <- as.character(Design$Design)
   Design$Design[Design$Design == "T30.T3x10"] <- "T30.3x10s"
   Design$Design[Design$Design == "T30.T6x5s"] <- "T30.6x5s"
   Design$NumPops <- as.numeric(as.character(Design$NumPops))
   head(Design)
```

### d) Create R replicate random samples of n = 30 sites

```{r subsets}
R = 10
Sites.30 <- list()
for(r in 1:R)
{
  Sites.30[[r]] <- sort(sample(1:90, 30, replace=FALSE))
}

# Alternative: split into quadrants
# ---------------------------------
# R = 4
# GroupX <- rep("A", 90)
# GroupX[coord[,1] < median(coord[,1])] <- "B"
# GroupY <- rep("C", 90)
# GroupY[coord[,2] <= median(coord[,2])] <- "D"
# Group <- factor(paste0(GroupX, GroupY))
# Sites.30 <- split(c(1:90), Group)


saveRDS(Sites.30, paste0(here::here(), "/output/Sites.30.rds"))
```


## 2. Genetic data

### a) Select datasets

Select all data files with the largest sample size (90) and random sampling (R)

```{r}
Sites.R.90 <- c(1:nrow(Design))[Design$NumPops==90 & Design$Type=="R"] 
```

Check parameters for selected datasets:

```{r}
Design[Sites.R.90,]
```

### b) Run function 'getGenData' to extract the genetic data

This function extracts the genetic data, selects the 9900 neutral loci, and adds a first column 'pop' with site as a factor. This is the format for functions in the package `hierfstat`.

Define function:

```{r getGenData}
getGenData <- function(j)
{
  # Select the sites that need to be sampled for this run:
  i=Sites.R.90[j]
  cat("j:", j, ", i:", i, "\n")
  
  # Each file has NumPops x NumInd rows (sampled individuals) and up to 10000 columns (loci)
  tmp <- read.table(paste0(here::here(),"/dryad/SimFilesLFMM/", Filenames.lfmm[[i]]))
  
  # Drop non-neutral loci
  tmp <- tmp[,1:9900]
    
  # Site: create vector of sites = pops (for each row = individual)
  Site <- rep(1:Design$NumPops[i],each=as.numeric(as.vector(Design$NumInd)[i]))
  
  #Data.hierfstat <- data.frame(pop=factor(Site), tmp)
  Data.hierfstat <- data.frame(pop=Site, tmp)
  
  return(Data.hierfstat)
}
```

Run in parallel and save results:

```{r GenData90}
start_time <- Sys.time()

Index.j <- 1:length(Sites.R.90)

Data.R.90 <- mclapply(Index.j, function(j) getGenData(j),
                 mc.cores=detectCores())
names(Data.R.90) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Data.R.90, paste0(here::here(), "/output/Data.R.90.rds"))
```

Results are stored in a list (one element per site j with 90 samples), with each element:

- Data.frame with first column "pop" (factor of site IDs) and 9900 columns of neutral loci
    
### c) Run function 'getDgen' to calculate sample Fst and genetic distances

Define function:

```{r getDgen}
#Data.R.90 <- readRDS(paste0(here::here(), "/output/Data.R.90.rds"))

getDgen <- function(j, Data=Data.R.90, dist.method = c("Fst", "Dch"), nLoci=9900)
{
  Fst <- basic.stats(Data[[j]][,1:(nLoci+1)])$overall

  Fst.30 <- t(sapply(1:length(Sites.30), function(s) 
    basic.stats(filter(Data[[j]][, 1:(nLoci+1)], is.element(pop, Sites.30[[s]])))$overall))
  
  D <- list()
  for(k in 1:length(dist.method))
  {
    D[[k]] <- genet.dist(Data[[j]][,1:(nLoci+1)], method = dist.method[k])
  }
  names(D) <- dist.method
  
  return(list(Fst=Fst, Fst.30 = Fst.30, Dgen=D))
}
```

Run in parallel and save results: (this takes a longer time: 10.4 min on Helene's iMac)

```{r Dgen90}
start_time <- Sys.time()

Index.j <- 1:length(Sites.R.90)

Dgen.R.90 <- mclapply(Index.j, function(j) getDgen(j, Data=Data.R.90, nLoci=9900, 
                                                 dist.method=c("Fst", "Dch")),
                 mc.cores=detectCores())
names(Dgen.R.90) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Dgen.R.90, paste0(here::here(), "/output/Dgen.R.90.rds"))
```

Repeat for first 3300 loci

(Note: no effect of locus number on variability, i.e., first 3300 can be considered a random sample as much as any other subset of 3300)

```{r Dgen90.3}
start_time <- Sys.time()

Index.j <- 1:length(Sites.R.90)

Dgen.R.90.3 <- mclapply(Index.j, function(j) getDgen(j, Data=Data.R.90, nLoci=3300,
                                                 dist.method=c("Fst", "Dch")),
                 mc.cores=detectCores())
names(Dgen.R.90.3) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Dgen.R.90.3, paste0(here::here(), "/output/Dgen.R.90.3.rds"))
```

Repeat for 500 loci

```{r Dgen90.500}
start_time <- Sys.time()

Index.j <- 1:length(Sites.R.90)

Dgen.R.90.500 <- mclapply(Index.j, function(j) getDgen(j, Data=Data.R.90, nLoci=500,
                                                 dist.method=c("Fst", "Dch")),
                 mc.cores=detectCores())
names(Dgen.R.90.500) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Dgen.R.90.500, paste0(here::here(), "/output/Dgen.R.90.500.rds"))
```

Results are stored in a list (one element per site j with 90 samples) with these elements:

- Fst: vector with 'overall' statistics returned by `basic.stats` function
- Fst.30: matrix with statistics for ten subsets of n = 30 sites
- Dgen: list of pairwise genetic distance matrices
    - Fst (Fst)
    - Cavalli-Sforza and Edwards Chord distance (Dch)

### d) Run function 'getMEMgene' to obtain RsqAdj and Moran's I

This function extracts the grid coordinates, performs memgene analysis with forward selection to obtain the adjusted Rsquare. It also calculates the raw (unadjusted) Rsquare, then calculates Moran's I for the genetic data by obtaining a scalogram S (Rsquare for each MEM vector, which sum to 1 across all MEM vectors) and multiplying with the rescaled MEM eigenvectors (Moran's I for each vector). It also returns the limits for Moran's I of the genetic data (min and max of Moran's I values of MEM vectors).

Define function:

```{r getMEMgene}
getMEMgene <- function(j, Dgen = Dgen.R.90, subset=NULL)
{
  i=Sites.R.90[j]
  cat("j:", j, ", i:", i, "\n")
  
  # Extract the grid coordinates of the sampled sites
  coord <- data.matrix(Coords[[as.numeric(Design$Type[i])]]
                     [[as.numeric(Design$Env[i])]][,2:3])
  if(length(subset) > 0)
  {
     coord <- coord[subset,]
  }
  
  Res <- list()
  for(k in 1: length(Dgen[[j]]$Dgen))
  {
    
    Y <- as.matrix(Dgen[[j]]$Dgen[[k]])
    
    if(length(subset) > 0)
    {
       Y <- Y[subset, subset]
    }
    
    # memGene
    
    MEM <- mgMEM(dist(coord))

    Positive <- mgForward(Y, MEM$vectorsMEM[ , MEM$valuesMEM > 0])
    Negative <- mgForward(Y,MEM$vectorsMEM[ , MEM$valuesMEM < 0])
    allSelected <- cbind(MEM$vectorsMEM[, MEM$valuesMEM > 0][,na.omit(Positive$selectedMEM)],
                     MEM$vectorsMEM[, MEM$valuesMEM < 0][,na.omit(Negative$selectedMEM)])
    RsqAdj = RsqAdjPos =Rsq = 0
    if(ncol(allSelected) > 0)
    {
      MEM$analysis <- mgRDA(Y, allSelected, full=TRUE)
      RsqAdj <- MEM$analysis$RsqAd
      Rsq <- sum(diag(MEM$analysis$pred)) / (sum(diag(MEM$analysis$pred)) +
                                             sum(diag(MEM$analysis$resid)))
      if(length(Positive$selectedMEM) > 0) 
      {
        RsqAdjPos <- mgRDA(Y, allSelected[,1:length(Positive$selectedMEM)], full=TRUE)$RsqAd
      }
    } 

    # Centre distance matrix
    n <- nrow(Y)
    row.wt = rep(1, nrow(Y))
    col.wt = rep(1, ncol(Y))
    st <- sum(col.wt)
    sr <- sum(row.wt)
    row.wt <- row.wt/sr
    col.wt <- col.wt/st
    Y <- -0.5 * (Y * Y)
    row.mean <- apply(row.wt * Y, 2, sum)
    col.mean <- apply(col.wt * t(Y), 2, sum)
    col.mean <- col.mean - sum(row.mean * col.wt)
    Y <- sweep(Y, 2, row.mean)
    G <- t(sweep(t(Y), 2, col.mean))
    
    # Get Rsq for each MEM vector from a separate dbRDA for each vector m
    X <- MEM$vectorsMEM
  
    S <- rep(0, ncol(X))
    for(m in 1:ncol(X))
    {
      if(var(X[,m]) > 0)
      {
        p = 1
        H <- X[,m] %*% solve(t(X[,m]) %*% X[,m]) %*% t(X[,m])
        I <- diag(n)
        res <- (I - H) %*% G %*% (I - H)
        S[m] <- 1 - sum(diag(res))/sum(diag(G))
      }
    }
    
    #HW: check why these corrections are needed:  
    S[S < 0] <- 0
    S = S / sum(S)
    
    tmp <- mgW.HW(dist(coord))
    
    # Get Moran's I
    Values <- MEM$valuesMEM / abs(sum(MEM$valuesMEM))
    Range <- range(Values)
    Morans.I <- as.vector(S %*% Values)
    I.sd <- ape::Moran.I(rnorm(n), mgW.HW(dist(coord)))$sd
    C <- diag(t(sqrt(S)) %*% diag(Values^2) %*% sqrt(S))
    Rho <- Morans.I / sqrt(C)
    
    Res[[k]] <- list(RsqAdj=RsqAdj, RsqAdjPos=RsqAdjPos, Rsq=Rsq, Morans.I=Morans.I, 
                     C=C, Rho=Rho, Range=Range, I.sd=I.sd)
  }
  names(Res) <- names(Dgen[[1]]$Dgen)
  
  return(Res)
}
```

Run function in parallel:

```{r MEMgene90}
#Dgen.R.90 <- readRDS(paste0(here::here(), "/output/Dgen.R.90.rds"))

start_time <- Sys.time() 

Index.j <- 1:length(Sites.R.90)

Results.R.90 <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90, subset=NULL),
                    mc.cores=detectCores())
names(Results.R.90) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.R.90, paste0(here::here(), "/output/Results.R.90.rds"))
```

Repeat for 3300 loci

```{r MEMgene90.3}
#Dgen.R.90.3 <- readRDS(paste0(here::here(), "/output/Dgen.R.90.3.rds"))

start_time <- Sys.time() 

Index.j <- 1:length(Sites.R.90)

Results.R.90.3 <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90.3, subset=NULL),
                    mc.cores=detectCores())
names(Results.R.90.3) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.R.90.3, paste0(here::here(), "/output/Results.R.90.3.rds"))
```

Repeat for 500 loci

```{r MEMgene90.500}
start_time <- Sys.time() 

Index.j <- 1:length(Sites.R.90)

Results.R.90.500 <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90.500, subset=NULL),
                    mc.cores=detectCores())
names(Results.R.90.500) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.R.90.500, paste0(here::here(), "/output/Results.R.90.500.rds"))
```

Results are stored in a list (one element per site j with 90 samples) with these elements:

- List with one element per genetic distance measure:
  - RsqAdj: adjusted Rsquare from default analysis with memgene
  - Rsq: unadjusted Rsquare from default analysis with memgene
  - Morans.I: Moran's I for the genetic data
  - Range: range (minimum and maximum) of Moran's I of MEM vectors (limits for Moran's I of genetic data)

  
## 3. Compile results for n = 90

Import results without overwriting:

```{r}
Results <- readRDS(paste0(here::here(), "/output/Results.R.90.rds"))
Results.3 <- readRDS(paste0(here::here(), "/output/Results.R.90.3.rds"))
Results.500 <- readRDS(paste0(here::here(), "/output/Results.R.90.500.rds"))

D <- readRDS(paste0(here::here(), "/output/Dgen.R.90.rds"))
D.3 <- readRDS(paste0(here::here(), "/output/Dgen.R.90.3.rds"))
D.500 <- readRDS(paste0(here::here(), "/output/Dgen.R.90.500.rds"))
```

Function to extract response variables

```{r}
getRes <- function(Results=Results, k = 1)
{
  RsqAdj = sapply(Results, function(ls) ls[[k]]$RsqAdj)
  RsqAdjPos = sapply(Results, function(ls) ls[[k]]$RsqAdjPos)
  Rsq = sapply(Results, function(ls) ls[[k]]$Rsq)
  Morans.I = sapply(Results, function(ls) ls[[k]]$Morans.I)
  C = sapply(Results, function(ls) ls[[k]]$C)
  Rho = sapply(Results, function(ls) ls[[k]]$Rho)
  I.max = sapply(Results, function(ls) max(ls[[k]]$Range))
  I.min = sapply(Results, function(ls) min(ls[[k]]$Range))
  I.sd = sapply(Results, function(ls) ls[[k]]$I.sd)
  I.scaled = Morans.I / I.max
  I.scaled2 = 2 * (Morans.I - I.min)/(I.max - I.min) - 1
  I.z = Morans.I / I.sd
  res <- data.frame(RsqAdj=RsqAdj, RsqAdjPos=RsqAdjPos, Rsq=Rsq, Morans.I=Morans.I, C=C, Rho=Rho,
                    I.max=I.max, I.min=I.min, I.scaled=I.scaled, I.scaled2=I.scaled2, I.z=I.z)
}
```

Combine response variables with Design matrix

```{r}
Ftab <- data.frame(Fst.90 = sapply(D, function(ls) ls$Fst[7]),
                   Fst.30.m = sapply(D, function(ls) mean(ls$Fst.30[,7])),
                   Fst.30.s = sapply(D, function(ls) sd(ls$Fst.30[,7])),
                   Fst.90.3 = sapply(D.3, function(ls) ls$Fst[7]),
                   Fst.30.m.3 = sapply(D.3, function(ls) mean(ls$Fst.30[,7])),
                   Fst.30.s.3 = sapply(D.3, function(ls) sd(ls$Fst.30[,7])),
                   Fst.90.500 = sapply(D.500, function(ls) ls$Fst[7]),
                   Fst.30.m.500 = sapply(D.500, function(ls) mean(ls$Fst.30[,7])),
                   Fst.30.s.500 = sapply(D.500, function(ls) sd(ls$Fst.30[,7])))

res <- lapply(c(1:length(Results[[1]])), function(k) getRes(Results, k))
res.3 <- lapply(c(1:length(Results.3[[1]])), function(k) getRes(Results.3, k))
res.500 <- lapply(c(1:length(Results.500[[1]])), function(k) getRes(Results.500, k))
names(res) <- names(res.3) <-names(res.500) <-names(Results[[1]])

res.combined <- Reduce(cbind, res)
res.3.combined <- Reduce(cbind, res.3)
res.500.combined <- Reduce(cbind, res.500)
names(res.combined) <- paste(rep(names(Results[[1]]), each=ncol(res[[1]])), 
                             names(res[[1]]), "90", sep=".")
names(res.3.combined) <- paste(names(res.combined), "3", sep=".")
names(res.500.combined) <- paste(names(res.combined), "500", sep=".")

Results.table <- data.frame(Design[Sites.R.90,], Ftab, res.combined, 
                            res.3.combined, res.500.combined)
saveRDS(Results.table, paste0(here::here(), "/output/Results.table.rds"))
Results.table

rm(list=c("Results", "Results.3", "Results.500", "D", "D.3", "D.500"))
```


Analyze according to the following factors:

- Demography (1R, 2R, IBD, IM)
- NumInd: 20, 6
- Genetic distance measure (Fst, Dch)
- Number of loci (9900 or 3300) (where variable names with .3 denote 3300 loci)

Response variables:

- RsqAdj: based on all MEM selected
- RsqAdjPos: as RsquAdj in memgene output with default settings (only positive MEM)
- Rsq: unadjusted (not reported in memgene)
- Morans.I: assuming population is sampled. Correct with (n-1)/n (where n = 90) for estimating population Moran's I
- Morans.I.scaled: this is experimental. Divide Morans.I by the maximum value (max(Range)).
- Morans.I.scaled2: this is experimental. Rescaled to range between [-1, 1]: `I.scaled2 = 2 * (I - min)/(max - min) - 1`

Notes:

- Env: for each combination, there are three replicate datasets (Env: 453, 988, 950). Env could be used as a blocking variable.


## 4. Analyze data for subsets with 30 pops

### a) Repeat MEMgene with n = 30

The R = 10 subsets of n = 30 sites for each dataset with n = 90 sites were defined above already in object `Sites.30`.

```{r MEMgene30}
start_time <- Sys.time()

Index.j <- 1:length(Sites.R.90)
R = length(Sites.30)
Results.R.30 <- rep( list(list()), R)

for(r in 1:R)
{
  Results.R.30[[r]] <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90,
                                                       subset=Sites.30[[r]]),
                                mc.cores=detectCores())
  names(Results.R.30[[r]]) <- Sites.R.90
}

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.R.30, paste0(here::here(), "/output/Results.R.30.rds"))
```

Repeat for 3300 loci

```{r MEMgene30.3}
start_time <- Sys.time()

Results.R.30.3 <- rep( list(list()), R)

for(r in 1:R)
{
  Results.R.30.3[[r]] <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90.3,
                                                       subset=Sites.30[[r]]),
                                mc.cores=detectCores())
  names(Results.R.30.3[[r]]) <- Sites.R.90
}

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.R.30.3, paste0(here::here(), "/output/Results.R.30.3.rds"))
```

Repeat for 500 loci

```{r MEMgene30.500}
start_time <- Sys.time()

Results.R.30.500 <- rep( list(list()), R)

for(r in 1:R)
{
  Results.R.30.500[[r]] <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90.500,
                                                       subset=Sites.30[[r]]),
                                mc.cores=detectCores())
  names(Results.R.30.500[[r]]) <- Sites.R.90
}

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.R.30.500, paste0(here::here(), "/output/Results.R.30.500.rds"))
```

### b) Compile results for n = 30

Determine mean and sdev among the R = 10 replicate subsets for each datasest with 90 pops.

Import results without overwriting:

```{r}
Results.subsets <- readRDS(paste0(here::here(), "/output/Results.R.30.rds"))
Results.3.subsets <- readRDS(paste0(here::here(), "/output/Results.R.30.3.rds"))
Results.500.subsets <- readRDS(paste0(here::here(), "/output/Results.R.30.500.rds"))
```

Combine mean and sdev of response variables with Design matrix:

Note: dropped Rsq due to errors when knitting.

```{r}
res.r <- lapply(Results.subsets, function(sub) 
  lapply(c(1:length(Results.subsets[[1]][[1]])), function(k) getRes(sub, k)))
res.r.3 <- lapply(Results.3.subsets, function(sub) 
  lapply(c(1:length(Results.3.subsets[[1]][[1]])), function(k) getRes(sub, k)))
res.r.500 <- lapply(Results.500.subsets, function(sub) 
  lapply(c(1:length(Results.500.subsets[[1]][[1]])), function(k) getRes(sub, k)))

tmp <- list()
for(k in 1:length(res.r[[1]]))
  {
    RsqAdj.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdj), 1, mean)
    RsqAdj.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdj), 1, sd)
    RsqAdjPos.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdjPos), 1, mean)
    RsqAdjPos.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdjPos), 1, sd)
    Morans.I.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$Morans.I), 1, mean)
    Morans.I.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$Morans.I), 1, sd)
    C.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$C), 1, mean)
    C.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$C), 1, sd)
    Rho.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$Rho), 1, mean)
    Rho.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$Rho), 1, sd)
    I.scaled.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled), 1, mean)
    I.scaled.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled), 1, sd)
    I.scaled2.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled2), 1, mean)
    I.scaled2.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled2), 1, sd)
    I.z.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$I.z), 1, mean)
    I.z.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$I.z), 1, sd)
  
    tmp[[k]] <- data.frame(RsqAdj.30.m=RsqAdj.30.m, RsqAdj.30.s=RsqAdj.30.s, 
                           RsqAdjPos.30.m=RsqAdjPos.30.m, RsqAdjPos.30.s=RsqAdjPos.30.s, 
                           Morans.I.30.m=Morans.I.30.m, Morans.I.30.s=Morans.I.30.s,
                           C.30.m=C.30.m, C.30.s=C.30.s, Rho.30.m=Rho.30.m, Rho.30.s=Rho.30.s,
                           I.scaled.30.m=I.scaled.30.m, I.scaled.30.s=I.scaled.30.s,
                           I.scaled2.30.m=I.scaled2.30.m, I.scaled2.30.s=I.scaled2.30.s,
                           I.z.30.m=I.z.30.m, I.z.30.s=I.z.30.s)
}

tmp.3 <- list()
for(k in 1:length(res.r[[1]]))
  {
    RsqAdj.30.m <- apply(sapply(res.r.3, function(sub) sub[[k]]$RsqAdj), 1, mean)
    RsqAdj.30.s <- apply(sapply(res.r.3, function(sub) sub[[k]]$RsqAdj), 1, sd)
    RsqAdjPos.30.m <- apply(sapply(res.r.3, function(sub) sub[[k]]$RsqAdjPos), 1, mean)
    RsqAdjPos.30.s <- apply(sapply(res.r.3, function(sub) sub[[k]]$RsqAdjPos), 1, sd)
    Morans.I.30.m <- apply(sapply(res.r.3, function(sub) sub[[k]]$Morans.I), 1, mean)
    Morans.I.30.s <- apply(sapply(res.r.3, function(sub) sub[[k]]$Morans.I), 1, sd)
    C.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$C), 1, mean)
    C.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$C), 1, sd)
    Rho.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$Rho), 1, mean)
    Rho.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$Rho), 1, sd)
    I.scaled.30.m <- apply(sapply(res.r.3, function(sub) sub[[k]]$I.scaled), 1, mean)
    I.scaled.30.s <- apply(sapply(res.r.3, function(sub) sub[[k]]$I.scaled), 1, sd)
    I.scaled2.30.m <- apply(sapply(res.r.3, function(sub) sub[[k]]$I.scaled2), 1, mean)
    I.scaled2.30.s <- apply(sapply(res.r.3, function(sub) sub[[k]]$I.scaled2), 1, sd)
    I.z.30.m <- apply(sapply(res.r.3, function(sub) sub[[k]]$I.z), 1, mean)
    I.z.30.s <- apply(sapply(res.r.3, function(sub) sub[[k]]$I.z), 1, sd)
    
    tmp.3[[k]] <- data.frame(RsqAdj.30.3.m=RsqAdj.30.m, RsqAdj.30.3.s=RsqAdj.30.s, 
                           RsqAdjPos.30.3.m=RsqAdjPos.30.m, RsqAdjPos.30.3.s=RsqAdjPos.30.s, 
                           Morans.I.30.3.m=Morans.I.30.m, Morans.I.30.3.s=Morans.I.30.s,
                           C.30.3.m=C.30.m, C.30.3.s=C.30.s, 
                           Rho.30.3.m=Rho.30.m, Rho.30.3.s=Rho.30.s,
                           I.scaled.30.3.m=I.scaled.30.m, I.scaled.30.3.s=I.scaled.30.s,
                           I.scaled2.30.3.m=I.scaled2.30.m, I.scaled2.30.3.s=I.scaled2.30.s,
                           I.z.30.3.m=I.z.30.m, I.z.30.3.s=I.z.30.s)
}

tmp.500 <- list()
for(k in 1:length(res.r[[1]]))
  {
    RsqAdj.30.m <- apply(sapply(res.r.500, function(sub) sub[[k]]$RsqAdj), 1, mean)
    RsqAdj.30.s <- apply(sapply(res.r.500, function(sub) sub[[k]]$RsqAdj), 1, sd)
    RsqAdjPos.30.m <- apply(sapply(res.r.500, function(sub) sub[[k]]$RsqAdjPos), 1, mean)
    RsqAdjPos.30.s <- apply(sapply(res.r.500, function(sub) sub[[k]]$RsqAdjPos), 1, sd)
    Morans.I.30.m <- apply(sapply(res.r.500, function(sub) sub[[k]]$Morans.I), 1, mean)
    Morans.I.30.s <- apply(sapply(res.r.500, function(sub) sub[[k]]$Morans.I), 1, sd)
    C.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$C), 1, mean)
    C.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$C), 1, sd)
    Rho.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$Rho), 1, mean)
    Rho.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$Rho), 1, sd)
    I.scaled.30.m <- apply(sapply(res.r.500, function(sub) sub[[k]]$I.scaled), 1, mean)
    I.scaled.30.s <- apply(sapply(res.r.500, function(sub) sub[[k]]$I.scaled), 1, sd)
    I.scaled2.30.m <- apply(sapply(res.r.500, function(sub) sub[[k]]$I.scaled2), 1, mean)
    I.scaled2.30.s <- apply(sapply(res.r.500, function(sub) sub[[k]]$I.scaled2), 1, sd)
    I.z.30.m <- apply(sapply(res.r.500, function(sub) sub[[k]]$I.z), 1, mean)
    I.z.30.s <- apply(sapply(res.r.500, function(sub) sub[[k]]$I.z), 1, sd)
    
    tmp.500[[k]] <- data.frame(RsqAdj.30.500.m=RsqAdj.30.m, RsqAdj.30.500.s=RsqAdj.30.s, 
                           RsqAdjPos.30.500.m=RsqAdjPos.30.m, RsqAdjPos.30.500.s=RsqAdjPos.30.s, 
                           Morans.I.30.500.m=Morans.I.30.m, Morans.I.30.500.s=Morans.I.30.s,
                           C.30.500.m=C.30.m, C.30.500.s=C.30.s, 
                           Rho.30.500.m=Rho.30.m, Rho.30.500.s=Rho.30.s,
                           I.scaled.30.500.m=I.scaled.30.m, I.scaled.30.500.s=I.scaled.30.s,
                           I.scaled2.30.500.m=I.scaled2.30.m, I.scaled2.30.500.s=I.scaled2.30.s,
                           I.z.30.500.m=I.z.30.m, I.z.30.500.s=I.z.30.s)
}

res.r.combined <- Reduce(cbind, tmp)
res.r.3.combined <- Reduce(cbind, tmp.3)
res.r.500.combined <- Reduce(cbind, tmp.500)
names(res.r.combined) <- paste(rep(names(Results.subsets[[1]][[1]]), each=ncol(tmp[[1]])), 
                             names(tmp[[1]]), sep=".")
names(res.r.3.combined) <- paste(rep(names(Results.subsets[[1]][[1]]), each=ncol(tmp[[1]])), 
                             names(tmp.3[[1]]), sep=".")
names(res.r.500.combined) <- paste(rep(names(Results.subsets[[1]][[1]]), each=ncol(tmp[[1]])), 
                             names(tmp.500[[1]]), sep=".")


Results.subsets.table <- data.frame(Results.table, res.r.combined, 
                                    res.r.3.combined, res.r.500.combined)
saveRDS(Results.subsets.table, paste0(here::here(), "/output/Results.subsets.table.rds"))
Results.subsets.table
```

Get maximum possible Moran's I for each subsample (same for all 90 datasets):

```{r}
I.max.30 <- sapply(Results.subsets, function(sub) max(sub[[1]][[1]]$Range))
I.min.30 <- sapply(Results.subsets, function(sub) min(sub[[1]][[1]]$Range))
data.frame(I.max.30, I.min.30)
```

## 5. Analyze results for n = 90

### a) Effect of Demography

```{r fig.height=5, fig.width=8}
par(mfrow=c(2,4))
with(Results.subsets.table, boxplot(Fst.RsqAdjPos.90 ~ Demography,
     main="Fst.RsqAdjPos", ylim=c(0,1)))
with(Results.subsets.table, boxplot(Fst.Morans.I.90 ~ Demography,
     main="Fst.Morans.I", ylim=c(0,1)))
#with(Results.subsets.table, boxplot(Fst.I.scaled.90 ~ Demography,
#     main="Fst.I.scaled", ylim=c(-0.5,1)))
#lines(c(0,10), c(0,0), lty=2)
#with(Results.subsets.table, boxplot(Fst.I.scaled2.90 ~ Demography,
#     main="Fst.I.scaled2", ylim=c(-0.5,1)))
#lines(c(0,10), c(0,0), lty=2)
with(Results.subsets.table, boxplot(Fst.C.90 ~ Demography,
     main="Fst.C", ylim=c(0,1)))
with(Results.subsets.table, boxplot(Fst.Rho.90 ~ Demography,
     main="Fst.Rho", ylim=c(0,1)))


with(Results.subsets.table, boxplot(Dch.RsqAdjPos.90 ~ Demography,
     main="Dch.RsqAdjPos", ylim=c(0,1)))
with(Results.subsets.table, boxplot(Dch.Morans.I.90 ~ Demography,
     main="Dch.Morans.I", ylim=c(0,1)))
#with(Results.subsets.table, boxplot(Dch.I.scaled.90 ~ Demography,
#     main="Dch.I.scaled", ylim=c(-0.5,1)))
#lines(c(0,10), c(0,0), lty=2)
#with(Results.subsets.table, boxplot(Dch.I.scaled2.90 ~ Demography,
#     main="Dch.I.scaled2", ylim=c(-0.5,1)))
#lines(c(0,10), c(0,0), lty=2)
with(Results.subsets.table, boxplot(Dch.C.90 ~ Demography,
     main="Dch.C", ylim=c(0,1)))
with(Results.subsets.table, boxplot(Dch.Rho.90 ~ Demography,
     main="Dch.Rho", ylim=c(0,1)))
par(mfrow=c(1,1))
```
**Interpretation:**

- As expected, island model (IM) does not show spatial structure.
- Differences between 1R and 2R larger for Moran's I than RsqAdj.
- Note: all datasets with n = 90 have the same samplign design and thus the same maximum value for Moran's I of the genetic data, hence rescaling does not change the pattern, only the absolute values.
- Rescaling Moran's I for both min and max (I.scaled2) is not helpful.
- Same patterns for Fst and Dch.


### b) Effect of number of individuals

Drop IM

```{r fig.height=5, fig.width=8}
Results.subsets.table$NumInd <- factor(as.character(Results.subsets.table$NumInd))
a <- which(Results.subsets.table$Demography != "IM")
#a <- which(Results.subsets.table$Demography != "IM" & Results.subsets.table$NumInd == 20)

par(mfrow=c(2,4))
with(Results.subsets.table[a,], boxplot(Fst.RsqAdjPos.90 ~ NumInd,
     main="Fst.RsqAdjPos", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(Fst.Morans.I.90 ~ NumInd,
     main="Fst.Morans.I", ylim=c(0,1)))
#with(Results.subsets.table[a,], boxplot(Fst.I.scaled.90 ~ NumInd,
#     main="Fst.I.scaled", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(Fst.C.90 ~ NumInd,
     main="Fst.C", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(Fst.Rho.90 ~ NumInd,
     main="Fst.Rho", ylim=c(0,1)))

with(Results.subsets.table[a,], boxplot(Dch.RsqAdjPos.90 ~ NumInd,
     main="Dch.RsqAdjPos", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(Dch.Morans.I.90 ~ NumInd,
     main="Dch.Morans.I", ylim=c(0,1)))
#with(Results.subsets.table[a,], boxplot(Dch.I.scaled.90 ~ NumInd,
#     main="Dch.I.scaled", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(Dch.C.90 ~ NumInd,
     main="Dch.C", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(Dch.Rho.90 ~ NumInd,
     main="Dch.Rho", ylim=c(0,1)))

par(mfrow=c(1,1))
```

**Interpretation:**

- All measures are sensitive to the number of individuals sampled per population!
- Same patterns for Fst and Dch.
- Note as above: all datasets with n = 90 have the same samplign design and thus the same maximum value for Moran's I of the genetic data, hence rescaling does not change the pattern, only the absolute values.

### c) Effect of the number of loci

Drop IM

```{r fig.height=5, fig.width=8}
par(mfrow=c(2,4))
with(Results.subsets.table[a,], boxplot(list("500"=Fst.RsqAdjPos.90.500,
                                         "3300"=Fst.RsqAdj.90.3, "9900"=Fst.RsqAdj.90),
     main="Fst.RsqAdjPos, n=90", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("500"=Fst.Morans.I.90.500,
                                         "3300"=Fst.Morans.I.90.3, "9900"=Fst.Morans.I.90),
     main="Fst.Morans.I, n=90", ylim=c(0,1)))
#with(Results.subsets.table[a,], boxplot(list("500"=Fst.I.scaled.90.500,
#                                         "3300"=Fst.I.scaled.90.3, "9900"=Fst.I.scaled.90),
#     main="Fst.I.scaled, n=90", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("500"=Fst.C.90.500,
                                         "3300"=Fst.C.90.3, "9900"=Fst.C.90),
     main="Fst.C, n=90", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("500"=Fst.Rho.90.500,
                                         "3300"=Fst.Rho.90.3, "9900"=Fst.Rho.90),
     main="Fst.Rho, n=90", ylim=c(0,1)))


with(Results.subsets.table[a,], boxplot(list("500"=Fst.RsqAdjPos.30.500.m, 
                                         "3300"=Fst.RsqAdj.30.3.m, "9900"=Fst.RsqAdj.30.m),
     main="Fst.RsqAdjPos, n=30", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("500"=Fst.Morans.I.30.500.m, 
  "3300"=Fst.Morans.I.30.3.m, "9900"=Fst.Morans.I.30.m),
     main="Fst.Morans.I, n=30", ylim=c(0,1)))
#with(Results.subsets.table[a,], boxplot(list("500"=Fst.I.scaled.30.500.m, 
#                                         "3300"=Fst.I.scaled.30.3.m, "9900"=Fst.I.scaled.30.m),
#     main="Fst.I.scaled, n=30", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("500"=Fst.C.30.500.m, 
  "3300"=Fst.C.30.3.m, "9900"=Fst.C.30.m),
     main="Fst.C, n=30", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("500"=Fst.Rho.30.500.m, 
  "3300"=Fst.Rho.30.3.m, "9900"=Fst.Rho.30.m),
     main="Fst.Rho, n=30", ylim=c(0,1)))
par(mfrow=c(1,1))
```
**Interpretation:**

- No effect! Genetic resolution here depends on number of individuals, not loci??
- Double checked, will check again as this is counter intuitive.


## 6. Compare n = 30 to n = 90

### a) Fst by Demography and sample size

```{r}
par(mfcol=c(2,3))

with(Results.subsets.table, boxplot(Fst.30.m ~ Demography,
     main="Fst.30 (9900 loci)", ylim=c(0.011,0.015)))
with(Results.subsets.table, boxplot(Fst.90 ~ Demography,
     main="Fst.90 (9900 loci)", ylim=c(0.011,0.015)))

with(Results.subsets.table, boxplot(Fst.30.m.3 ~ Demography,
     main="Fst.30 (3300 loci)", ylim=c(0.011,0.015)))
with(Results.subsets.table, boxplot(Fst.90.3 ~ Demography,
     main="Fst.90 (3300 loci)", ylim=c(0.011,0.015)))

with(Results.subsets.table, boxplot(Fst.30.m.500 ~ Demography,
     main="Fst.30 (500 loci)", ylim=c(0.011,0.015)))
with(Results.subsets.table, boxplot(Fst.90.500 ~ Demography,
     main="Fst.90 (500 loci)", ylim=c(0.011,0.015)))

par(mfrow=c(1,1))
```

**Interpretation:**

- Fst robust towards number of loci or samples.
- Measures also non-spatial structure (IM model has similar Fst as 2R). In IM model, populations are differentiated but nearby populations are not more similar than distant ones.
- Why does 2R have lower Fst than 1R and IM?


### b) Compare response variables 

Drop IM

```{r fig.height=5, fig.width=8}
par(mfrow=c(2,3))
with(Results.subsets.table[a,], boxplot(list("30"=Fst.RsqAdjPos.30.m, "90"=Fst.RsqAdjPos.90),
     main="Fst.RsqAdjPos", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("30"=Fst.Morans.I.30.m, "90"=Fst.Morans.I.90),
     main="Fst.Morans.I", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("30"=Fst.I.scaled.30.m, "90"=Fst.I.scaled.90),
     main="Fst.I.scaled", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("30"=Fst.Rho.30.m, "90"=Fst.Rho.90),
     main="Fst.Rho", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("30"=Fst.C.30.m, "90"=Fst.C.90),
     main="Fst.C", ylim=c(0,1)))
#with(Results.subsets.table[a,], boxplot(list("30"=Fst.I.scaled2.30.m, "90"=Fst.I.scaled2.90),
#     main="Fst.I.scaled2", ylim=c(-0.5,1)))
with(Results.subsets.table[a,], boxplot(list("30"=Fst.I.z.30.m, "90"=Fst.I.z.90),
     main="Fst.I.z"))
par(mfrow=c(1,1))
```
**Interpretation:**

- All measures are sensitive to the number of populations sampled!
- Same patterns for Fst and Dch.
- Rescaled Moran's I more comparable than original Moran's I.


#### Account for sample size (Moran's I):

Cheng 2013: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0068336

Drop IM

```{r fig.height=3, fig.width=8}
par(mfrow=c(1,3))
with(Results.subsets.table[a,], boxplot(list("30"=Fst.Morans.I.30.m * 29/30, 
                                         "90"=Fst.Morans.I.90 *89/90),
     main="Fst.Morans.I", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("30"=Fst.I.scaled.30.m * 29/30,
                                         "90"=Fst.I.scaled.90*89/90),
     main="Fst.I.scaled", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("30"=Fst.I.scaled2.30.m * 29/30,
                                         "90"=Fst.I.scaled2.90*89/90),
     main="Fst.I.scaled2", ylim=c(-0.5,1)))
lines(c(0,10), c(0,0), lty=3)
par(mfrow=c(1,1))
```
**Interpretation:**

- The correction by Cheng (2013): `I' = I * (n-1)/n)` makes the differences between sample sizes larger, not smaller.
- Same patterns for Fst and Dch.


### c) Paired t-tests  (without IM)

Paired t-tests for difference between mean of subsamples with n = 30 and corresponding datasets with n = 90 sites.

**Interpretation:**

- All differences are highly significant.

```{r}
with(Results.subsets.table[a,], t.test(Fst.RsqAdjPos.30.m, Fst.RsqAdjPos.90, paired=TRUE))

with(Results.subsets.table[a,], t.test(Fst.Morans.I.30.m, Fst.Morans.I.90, paired=TRUE))

with(Results.subsets.table[a,], t.test(Fst.C.30.m, Fst.C.90, paired=TRUE))

with(Results.subsets.table[a,], t.test(Fst.Rho.30.m, Fst.Rho.90, paired=TRUE))

with(Results.subsets.table[a,], t.test(Fst.I.scaled.30.m, Fst.I.scaled.90, paired=TRUE))

with(Results.subsets.table[a,], t.test(Fst.I.scaled2.30.m, Fst.I.scaled2.90, paired=TRUE))

with(Results.subsets.table[a,], t.test(Fst.Morans.I.30.m * 29/30, 
                                         Fst.Morans.I.90 *89/90, paired=TRUE))
with(Results.subsets.table[a,], t.test(Fst.I.scaled.30.m * 29/30,
                                         Fst.I.scaled.90*89/90, paired=TRUE))
with(Results.subsets.table[a,], t.test(Fst.I.scaled2.30.m * 29/30,
                                         Fst.I.scaled2.90*89/90, paired=TRUE))
```

### d) Effect sizes (without IM)

Cohen's d for paired t-test. This is interesting!

**Interpretation:**

- Smallest effect size for RsqAdj (when all demographic scenarios are included)

Drop IM

```{r}
with(Results.subsets.table[a,], mean(Fst.RsqAdjPos.30.m - Fst.RsqAdjPos.90)/ 
       sd(Fst.RsqAdj.30.m - Fst.RsqAdj.90))

with(Results.subsets.table[a,], mean(Fst.Morans.I.30.m - Fst.Morans.I.90)/
       sd(Fst.Morans.I.30.m - Fst.Morans.I.90)) 

with(Results.subsets.table[a,], mean(Fst.C.30.m - Fst.C.90)/ 
       sd(Fst.C.30.m - Fst.C.90))

with(Results.subsets.table[a,], mean(Fst.Rho.30.m - Fst.Rho.90)/
       sd(Fst.Rho.30.m - Fst.Rho.90)) 

with(Results.subsets.table[a,], mean(Fst.I.scaled.30.m - Fst.I.scaled.90)/
       sd(Fst.I.scaled.30.m - Fst.I.scaled.90))

with(Results.subsets.table[a,], mean(Fst.I.scaled2.30.m - Fst.I.scaled2.90)/
       sd(Fst.I.scaled2.30.m - Fst.I.scaled2.90))

with(Results.subsets.table[a,], mean(Fst.Morans.I.30.m * 29/30 - Fst.Morans.I.90 *89/90) /
       sd(Fst.Morans.I.30.m * 29/30 - Fst.Morans.I.90 *89/90))

with(Results.subsets.table[a,], mean(Fst.I.scaled.30.m * 29/30 - Fst.I.scaled.90*89/90) /
       sd(Fst.I.scaled.30.m * 29/30 - Fst.I.scaled.90*89/90))

with(Results.subsets.table[a,], mean(Fst.I.scaled2.30.m * 29/30 - Fst.I.scaled2.90*89/90) /
       sd(Fst.I.scaled2.30.m * 29/30 - Fst.I.scaled2.90*89/90))
```

HW Notes:

- Power of forward selection? No, because Moran's I also affected
- Nearest neighbor distance? No, because problem persists for quadrant subsets
- Population vs. sample? No, because difference gets larger when corrected
- Moran's I bad estimator of rho? No, because rho not  better. C is somewhat better.
- z-score for null distribution of Moran's I? No, because z scores even more different


