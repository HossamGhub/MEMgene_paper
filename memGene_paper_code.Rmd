---
title: "MEMgene paper analysis"
output: 
  html_document:
    theme: flatly
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
      smooth_scroll: false
---

Analysis of simulated datasets from Lotterhos & Whitlock with the same random sampling of 90 sites as in Wagner et al. (2017).

Goal:

Design:

Genetic data:

Response variables:


## 1. Preparations

### a) Packages

```{r packages}
#library(adegenet)
library(hierfstat)
#library(spdep)
#library(adespatial)
library(memgene)
library(here)
library(parallel)
library(dplyr)
library(spdep)
```

### b) Import patial coordinates

```{r coords}
Coords <- list()
Coords$Pairs <- list()
# Coords$Pairs$E453 <- read.table("1351142954_453EnviMatPAIRS_ED.txt")
# Coords$Pairs$E988 <- read.table("1351142970_988EnviMatPAIRS_ED.txt")
# Coords$Pairs$E950 <- read.table("1351142986_950EnviMatPAIRS_ED.txt")
Coords$Transect <- list()
# Coords$Transect$E453 <- read.table("1351142954_453EnviMatTRANSECTS_ED_Design.txt")
# Coords$Transect$E988 <- read.table("1351142970_988EnviMatTRANSECTS_ED_Design.txt")
# Coords$Transect$E950 <- read.table("1351142986_950EnviMatTRANSECTS_ED_Design.txt")
Coords$Random <- list()
Coords$Random$E453 <- Coords$Random$E988 <- Coords$Random$E950 <- 
  read.table("SchemeRandom1.txt") # upload this file

# for(k in 1:length(Coords$Transect))
# {
#   names(Coords$Transect[[k]])[2:3] <- names(Coords$Pairs[[1]])[2:3]
#   Coords$Transect[[k]][,7:9][is.na(Coords$Transect[[k]][,7:9])] <- FALSE
# }
for(i in 1:length(Coords))
{
  if(length(Coords[[i]]) > 0)
  {
    for(k in 1:length(Coords[[i]]))
    {
      b <- order(Coords[[i]][[k]][,3], Coords[[i]][[k]][,2]) # Sort by y, then x
      Coords[[i]][[k]] <- Coords[[i]][[k]][b,]  # correct order!!
    }
  }
  
}
```

### c) Parameter space

Genetic data: find all file names in the folder "SimFilesLFMM" that contain 'lfmm':

```{r files}
Filenames.lfmm <- list.files(paste0(here::here(), "/dryad//SimFilesLFMM/"), pattern="lfmm") 

test <- Reduce(rbind, strsplit(Filenames.lfmm, split="[_=]"))
test <- cbind(test, Reduce(rbind, strsplit(test[,ncol(test)], split="[.]")))
tmp <- strsplit(test[,2], split="[.xs]")
test2 <- matrix(NA, nrow(test), 3)
for(i in 1:nrow(test)) test2[i,1:length(tmp[[i]])] <- tmp[[i]]
test2 <- gsub("[A-Z, a-z]","", test2)
test <- cbind(test, test2)
dimnames(test) <- list(NULL, c("Demography", "Design", "ID", "Env", "ID2", 
                               "V6", "NumPops", "V8", "V9", "NumInd", "Design2",
                               "NumPops2", "NumTrans", "NumInd2"))
```

Design matrix (parameter space): each row is one combination of parameter settings:

- Demography: single refugium (1R), two refugia (2R), isolation by distane (IBD), island model (IM)
- Design: sampling design (R, P, T; see below) and number of pops sampled
- Env: which of the three replicate landscapes '453', '950', '988'
- NumPops: how many populations are sampled
- NumInd: how many individuals sampled per pop
- Type: random (R), pairs (P), transects (T)

```{r Design}   
   Design <- as.data.frame(test[,c(1,2,4,7,10,13,14)])
   Design$Env <- ordered(Design$Env, levels=c(453,988,950))
   Design$Type <- ordered(substr(Design$Design, 1, 1), levels=c("P", "T", "R"))
   Design$Design <- as.character(Design$Design)
   Design$Design[Design$Design == "T30.T3x10"] <- "T30.3x10s"
   Design$Design[Design$Design == "T30.T6x5s"] <- "T30.6x5s"
   Design$NumPops <- as.numeric(as.character(Design$NumPops))
   head(Design)
```

### d) Create R replicate random samples of n = 30 sites

```{r subsets}
R = 10
Sites.30 <- list()
for(r in 1:R)
{
  Sites.30[[r]] <- sort(sample(1:90, 30, replace=FALSE))
}

# Alternative: split into quadrants
# ---------------------------------
# R = 4
# GroupX <- rep("A", 90)
# GroupX[coord[,1] < median(coord[,1])] <- "B"
# GroupY <- rep("C", 90)
# GroupY[coord[,2] <= median(coord[,2])] <- "D"
# Group <- factor(paste0(GroupX, GroupY))
# Sites.30 <- split(c(1:90), Group)


saveRDS(Sites.30, paste0(here::here(), "/output/Sites.30.rds"))
```


## 2. Genetic data

### a) Select datasets

Select all data files with the largest sample size (90) and random sampling (R)

```{r}
Sites.R.90 <- c(1:nrow(Design))[Design$NumPops==90 & Design$Type=="R"] 
```

Check parameters for selected datasets:

```{r}
Design[Sites.R.90,]
```

### b) Run function 'getGenData' to extract the genetic data

This function extracts the genetic data, selects the 9900 neutral loci, and adds a first column 'pop' with site as a factor. This is the format for functions in the package `hierfstat`.

Define function:

```{r getGenData}
getGenData <- function(j)
{
  # Select the sites that need to be sampled for this run:
  i=Sites.R.90[j]
  cat("j:", j, ", i:", i, "\n")
  
  # Each file has NumPops x NumInd rows (sampled individuals) and up to 10000 columns (loci)
  tmp <- read.table(paste0(here::here(),"/dryad/SimFilesLFMM/", Filenames.lfmm[[i]]))
  
  # Drop non-neutral loci
  tmp <- tmp[,1:9900]
    
  # Site: create vector of sites = pops (for each row = individual)
  Site <- rep(1:Design$NumPops[i],each=as.numeric(as.vector(Design$NumInd)[i]))
  
  #Data.hierfstat <- data.frame(pop=factor(Site), tmp)
  Data.hierfstat <- data.frame(pop=Site, tmp)
  
  return(Data.hierfstat)
}
```

Run in parallel and save results:

```{r GenData90}
start_time <- Sys.time()

Index.j <- 1:length(Sites.R.90)

Data.R.90 <- mclapply(Index.j, function(j) getGenData(j),
                 mc.cores=detectCores())
names(Data.R.90) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Data.R.90, paste0(here::here(), "/output/Data.R.90.rds"))
```

Results are stored in a list (one element per site j with 90 samples), with each element:

- Data.frame with first column "pop" (factor of site IDs) and 9900 columns of neutral loci
    
### c) Run function 'getDgen' to calculate sample Fst and genetic distances

Define function:

```{r getDgen}
#Data.R.90 <- readRDS(paste0(here::here(), "/output/Data.R.90.rds"))

getDgen <- function(j, Data=Data.R.90, dist.method = c("Fst", "Dch"), nLoci=9900)
{
  Fst <- basic.stats(Data[[j]][,1:(nLoci+1)])$overall

  Fst.30 <- t(sapply(1:length(Sites.30), function(s) 
    basic.stats(filter(Data[[j]][, 1:(nLoci+1)], is.element(pop, Sites.30[[s]])))$overall))
  
  D <- list()
  for(k in 1:length(dist.method))
  {
    D[[k]] <- genet.dist(Data[[j]][,1:(nLoci+1)], method = dist.method[k])
  }
  names(D) <- dist.method
  
  return(list(Fst=Fst, Fst.30 = Fst.30, Dgen=D))
}
```

Run in parallel and save results

```{r Dgen90}
start_time <- Sys.time()

Index.j <- 1:length(Sites.R.90)

Dgen.R.90 <- mclapply(Index.j, function(j) getDgen(j, Data=Data.R.90, nLoci=9900, 
                                                 dist.method=c("Fst", "Dch")),
                 mc.cores=detectCores())
names(Dgen.R.90) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Dgen.R.90, paste0(here::here(), "/output/Dgen.R.90.rds"))
```

Repeat for first 3300 loci

(Note: no effect of locus number on variability, i.e., first 3300 can be considered a random sample as much as any other subset of 3300)

```{r Dgen90.3}
start_time <- Sys.time()

Index.j <- 1:length(Sites.R.90)

Dgen.R.90.3 <- mclapply(Index.j, function(j) getDgen(j, Data=Data.R.90, nLoci=3300,
                                                 dist.method=c("Fst", "Dch")),
                 mc.cores=detectCores())
names(Dgen.R.90.3) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Dgen.R.90.3, paste0(here::here(), "/output/Dgen.R.90.3.rds"))
```

Repeat for 500 loci

```{r Dgen90.500}
start_time <- Sys.time()

Index.j <- 1:length(Sites.R.90)

Dgen.R.90.500 <- mclapply(Index.j, function(j) getDgen(j, Data=Data.R.90, nLoci=500,
                                                 dist.method=c("Fst", "Dch")),
                 mc.cores=detectCores())
names(Dgen.R.90.500) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Dgen.R.90.500, paste0(here::here(), "/output/Dgen.R.90.500.rds"))
```

Results are stored in a list (one element per site j with 90 samples) with these elements:

- Fst: vector with 'overall' statistics returned by `basic.stats` function
- Fst.30: matrix with statistics for ten subsets of n = 30 sites
- Dgen: list of pairwise genetic distance matrices
    - Fst (Fst)
    - Cavalli-Sforza and Edwards Chord distance (Dch)

### d) Run function 'getMEMgene' to obtain RsqAdj and Moran's I

This function extracts the grid coordinates, performs memgene analysis with forward selection to obtain the adjusted Rsquare. It also calculates Moran's I for the genetic data by obtaining a scalogram S (Rsquare for each MEM vector, which sum to 1 across all MEM vectors) and multiplying with the rescaled MEM eigenvectors (Moran's I for each vector). It also returns the limits for Moran's I of the genetic data (min and max of Moran's I values of MEM vectors).

Argument 'subset' specifies a subset of sites to be used (for samples with n = 30). Argument 'drop' specifies which sites should be dropped (for simulating missing sites).

Define function:

```{r getMEMgene}
getMEMgene <- function(j, Dgen = Dgen.R.90, subset=NULL, drop=NULL)
{
  i=Sites.R.90[j]
  cat("j:", j, ", i:", i, "\n")
  
  # Extract the grid coordinates of the sampled sites
  coord <- data.matrix(Coords[[as.numeric(Design$Type[i])]]
                     [[as.numeric(Design$Env[i])]][,2:3])
  if(length(subset) > 0)
  {
     coord <- coord[subset,]
  }
  
  if(length(drop) > 0) { coord.drop <- coord[-drop,]}
  
  Res <- list()
  for(k in 1: length(Dgen[[j]]$Dgen))
  {
    
    Y <- as.matrix(Dgen[[j]]$Dgen[[k]])
    if(length(drop) > 0) {Y = Y[-drop, -drop]}
    
    if(length(subset) > 0)
    {
       Y <- Y[subset, subset]
    }
    
    # memGene
    
    MEM <- mgMEM(dist(coord))
    
    if(length(drop) > 0) 
    {
      MEM$vectorsMEM <- MEM$vectorsMEM[-drop,]
    }

    Positive <- mgForward(Y, MEM$vectorsMEM[, MEM$valuesMEM > 0])

    RsqAdjPos = 0
    if(!is.na(Positive$selectedRsqAdj)) { RsqAdjPos = Positive$selectedRsqAdj}
    
    if(length(drop) > 0)
    {
      MEM.drop <- mgMEM(dist(coord.drop))
      
      Positive <- mgForward(Y, MEM.drop$vectorsMEM[ , MEM.drop$valuesMEM > 0])
      RsqAdjPos.drop = 0
      if(!is.na(Positive$selectedRsqAdj)) { RsqAdjPos.drop = Positive$selectedRsqAdj}
    }

    # Centre distance matrix
    n <- nrow(Y)
    row.wt = rep(1, nrow(Y))
    col.wt = rep(1, ncol(Y))
    st <- sum(col.wt)
    sr <- sum(row.wt)
    row.wt <- row.wt/sr
    col.wt <- col.wt/st
    Y <- -0.5 * (Y * Y)
    row.mean <- apply(row.wt * Y, 2, sum)
    col.mean <- apply(col.wt * t(Y), 2, sum)
    col.mean <- col.mean - sum(row.mean * col.wt)
    Y <- sweep(Y, 2, row.mean)
    G <- t(sweep(t(Y), 2, col.mean))
    
    # Get Rsq for each MEM vector from a separate dbRDA for each vector m
    X <- MEM$vectorsMEM
  
    S <- rep(0, ncol(X))
    for(m in 1:ncol(X))
    {
      if(var(X[,m]) > 0)
      {
        p = 1
        H <- X[,m] %*% solve(t(X[,m]) %*% X[,m]) %*% t(X[,m])
        I <- diag(n)
        res <- (I - H) %*% G %*% (I - H)
        S[m] <- 1 - sum(diag(res))/sum(diag(G))
      }
    }
    
    #Subsample correction
    S[S < 0] <- 0
    #S = S / sum(S)
    
    # Get Moran's I
    Values <- MEM$valuesMEM / abs(sum(MEM$valuesMEM))
    Range <- range(Values)
    Morans.I <- as.vector(S %*% Values)
    
    Res[[k]] <- list(RsqAdjPos=RsqAdjPos, Morans.I=Morans.I, Range=Range)
    
  }
  names(Res) <- names(Dgen[[1]]$Dgen)
  
  return(Res)
}
```

Run function in parallel:

```{r MEMgene90}
#Dgen.R.90 <- readRDS(paste0(here::here(), "/output/Dgen.R.90.rds"))

start_time <- Sys.time() 

Index.j <- 1:length(Sites.R.90)

Results.R.90 <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90, subset=NULL),
                    mc.cores=detectCores())
names(Results.R.90) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.R.90, paste0(here::here(), "/output/Results.R.90.rds"))
```

Repeat for 3300 loci

```{r MEMgene90.3}
#Dgen.R.90.3 <- readRDS(paste0(here::here(), "/output/Dgen.R.90.3.rds"))

start_time <- Sys.time() 

Index.j <- 1:length(Sites.R.90)

Results.R.90.3 <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90.3, subset=NULL),
                    mc.cores=detectCores())
names(Results.R.90.3) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.R.90.3, paste0(here::here(), "/output/Results.R.90.3.rds"))
```

Repeat for 500 loci

```{r MEMgene90.500}
start_time <- Sys.time() 

Index.j <- 1:length(Sites.R.90)

Results.R.90.500 <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90.500, subset=NULL),
                    mc.cores=detectCores())
names(Results.R.90.500) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.R.90.500, paste0(here::here(), "/output/Results.R.90.500.rds"))
```

Results are stored in a list (one element per site j with 90 samples) with these elements:

- List with one element per genetic distance measure:
  - RsqAdj: adjusted Rsquare from default analysis with memgene
  - Morans.I: Moran's I for the genetic data
  - Range: range (minimum and maximum) of Moran's I of MEM vectors (limits for Moran's I of genetic data)

  
## 3. Compile results for n = 90

Import results without overwriting:

```{r}
Results <- readRDS(paste0(here::here(), "/output/Results.R.90.rds"))
Results.3 <- readRDS(paste0(here::here(), "/output/Results.R.90.3.rds"))
Results.500 <- readRDS(paste0(here::here(), "/output/Results.R.90.500.rds"))

D <- readRDS(paste0(here::here(), "/output/Dgen.R.90.rds"))
D.3 <- readRDS(paste0(here::here(), "/output/Dgen.R.90.3.rds"))
D.500 <- readRDS(paste0(here::here(), "/output/Dgen.R.90.500.rds"))
```


Function
```{r}
getRes <- function(Results=Results, k = 1)
{
  S.tot = sapply(Results, function(ls) ls[[k]]$S.tot)
  S.min = sapply(Results, function(ls) ls[[k]]$S.min)
  RsqAdjPos = sapply(Results, function(ls) ls[[k]]$RsqAdjPos)
  Morans.I = sapply(Results, function(ls) ls[[k]]$Morans.I)
  I.max = sapply(Results, function(ls) max(ls[[k]]$Range))
  I.min = sapply(Results, function(ls) min(ls[[k]]$Range))
  I.scaled = Morans.I / I.max


  res <- data.frame(S.tot=S.tot, S.min=S.min, RsqAdjPos=RsqAdjPos, Morans.I=Morans.I,
                    I.max=I.max, I.min=I.min, I.scaled=I.scaled)
}
```


Combine response variables with Design matrix

```{r}
Ftab <- data.frame(Fst.90 = sapply(D, function(ls) ls$Fst[7]),
                   Fst.30.m = sapply(D, function(ls) mean(ls$Fst.30[,7])),
                   Fst.30.s = sapply(D, function(ls) sd(ls$Fst.30[,7])),
                   Fst.90.3 = sapply(D.3, function(ls) ls$Fst[7]),
                   Fst.30.m.3 = sapply(D.3, function(ls) mean(ls$Fst.30[,7])),
                   Fst.30.s.3 = sapply(D.3, function(ls) sd(ls$Fst.30[,7])),
                   Fst.90.500 = sapply(D.500, function(ls) ls$Fst[7]),
                   Fst.30.m.500 = sapply(D.500, function(ls) mean(ls$Fst.30[,7])),
                   Fst.30.s.500 = sapply(D.500, function(ls) sd(ls$Fst.30[,7])))

res <- lapply(c(1:length(Results[[1]])), function(k) getRes(Results, k))
res.3 <- lapply(c(1:length(Results.3[[1]])), function(k) getRes(Results.3, k))
res.500 <- lapply(c(1:length(Results.500[[1]])), function(k) getRes(Results.500, k))
names(res) <- names(res.3) <-names(res.500) <-names(Results[[1]])

res.combined <- Reduce(cbind, res)
res.3.combined <- Reduce(cbind, res.3)
res.500.combined <- Reduce(cbind, res.500)
names(res.combined) <- paste(rep(names(Results[[1]]), each=ncol(res[[1]])), 
                             names(res[[1]]), "90", sep=".")
names(res.3.combined) <- paste(names(res.combined), "3", sep=".")
names(res.500.combined) <- paste(names(res.combined), "500", sep=".")

Results.table <- data.frame(Design[Sites.R.90,], Ftab, res.combined, 
                            res.3.combined, res.500.combined)
saveRDS(Results.table, paste0(here::here(), "/output/Results.table.rds"))
Results.table

rm(list=c("Results", "Results.3", "Results.500", "D", "D.3", "D.500"))
```


Analyze according to the following factors:

- Demography (1R, 2R, IBD, IM)
- NumInd: 20, 6
- Genetic distance measure (Fst, Dch)
- Number of loci (9900 or 3300) (where variable names with .3 denote 3300 loci)

Response variables:

- RsqAdj: based on all MEM selected
- RsqAdjPos: as RsquAdj in memgene output with default settings (only positive MEM)
- Rsq: unadjusted (not reported in memgene)
- Morans.I: assuming population is sampled. Correct with (n-1)/n (where n = 90) for estimating population Moran's I
- Morans.I.scaled: this is experimental. Divide Morans.I by the maximum value (max(Range)).

Notes:

- Env: for each combination, there are three replicate datasets (Env: 453, 988, 950). Env could be used as a blocking variable.


## 4. Analyze data for subsets with 30 pops

### a) Repeat MEMgene with n = 30

The R = 10 subsets of n = 30 sites for each dataset with n = 90 sites were defined above already in object `Sites.30`.

```{r MEMgene30}
start_time <- Sys.time()

Index.j <- 1:length(Sites.R.90)
R = length(Sites.30)
Results.R.30 <- rep( list(list()), R)

for(r in 1:R)
{
  Results.R.30[[r]] <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90,
                                                       subset=Sites.30[[r]]),
                                mc.cores=detectCores())
  names(Results.R.30[[r]]) <- Sites.R.90
}

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.R.30, paste0(here::here(), "/output/Results.R.30.rds"))
```

Repeat for 3300 loci

```{r MEMgene30.3}
start_time <- Sys.time()

Results.R.30.3 <- rep( list(list()), R)

for(r in 1:R)
{
  Results.R.30.3[[r]] <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90.3,
                                                       subset=Sites.30[[r]]),
                                mc.cores=detectCores())
  names(Results.R.30.3[[r]]) <- Sites.R.90
}

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.R.30.3, paste0(here::here(), "/output/Results.R.30.3.rds"))
```

Repeat for 500 loci

```{r MEMgene30.500}
start_time <- Sys.time()

Results.R.30.500 <- rep( list(list()), R)

for(r in 1:R)
{
  Results.R.30.500[[r]] <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90.500,
                                                       subset=Sites.30[[r]]),
                                mc.cores=detectCores())
  names(Results.R.30.500[[r]]) <- Sites.R.90
}

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.R.30.500, paste0(here::here(), "/output/Results.R.30.500.rds"))
```

### b) Compile results for n = 30

Determine mean and sdev among the R = 10 replicate subsets for each datasest with 90 pops.

Import results without overwriting:

```{r}
Results.subsets <- readRDS(paste0(here::here(), "/output/Results.R.30.rds"))
Results.3.subsets <- readRDS(paste0(here::here(), "/output/Results.R.30.3.rds"))
Results.500.subsets <- readRDS(paste0(here::here(), "/output/Results.R.30.500.rds"))
```

Combine mean and sdev of response variables with Design matrix:

Note: dropped Rsq due to errors when knitting.

```{r}
res.r <- lapply(Results.subsets, function(sub) 
  lapply(c(1:length(Results.subsets[[1]][[1]])), function(k) getRes(sub, k)))
res.r.3 <- lapply(Results.3.subsets, function(sub) 
  lapply(c(1:length(Results.3.subsets[[1]][[1]])), function(k) getRes(sub, k)))
res.r.500 <- lapply(Results.500.subsets, function(sub) 
  lapply(c(1:length(Results.500.subsets[[1]][[1]])), function(k) getRes(sub, k)))

tmp <- list()
for(k in 1:length(res.r[[1]]))
  {
    RsqAdj.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdj), 1, mean)
    RsqAdj.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdj), 1, sd)
    RsqAdjPos.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdjPos), 1, mean)
    RsqAdjPos.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdjPos), 1, sd)
    Morans.I.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$Morans.I), 1, mean)
    Morans.I.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$Morans.I), 1, sd)
    I.scaled.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled), 1, mean)
    I.scaled.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled), 1, sd)
  
    tmp[[k]] <- data.frame(RsqAdj.30.m=RsqAdj.30.m, RsqAdj.30.s=RsqAdj.30.s, 
                           RsqAdjPos.30.m=RsqAdjPos.30.m, RsqAdjPos.30.s=RsqAdjPos.30.s, 
                           Morans.I.30.m=Morans.I.30.m, Morans.I.30.s=Morans.I.30.s,
                          
                           I.scaled.30.m=I.scaled.30.m, I.scaled.30.s=I.scaled.30.s)
}

tmp.3 <- list()
for(k in 1:length(res.r[[1]]))
  {
    RsqAdj.30.m <- apply(sapply(res.r.3, function(sub) sub[[k]]$RsqAdj), 1, mean)
    RsqAdj.30.s <- apply(sapply(res.r.3, function(sub) sub[[k]]$RsqAdj), 1, sd)
    RsqAdjPos.30.m <- apply(sapply(res.r.3, function(sub) sub[[k]]$RsqAdjPos), 1, mean)
    RsqAdjPos.30.s <- apply(sapply(res.r.3, function(sub) sub[[k]]$RsqAdjPos), 1, sd)
    Morans.I.30.m <- apply(sapply(res.r.3, function(sub) sub[[k]]$Morans.I), 1, mean)
    Morans.I.30.s <- apply(sapply(res.r.3, function(sub) sub[[k]]$Morans.I), 1, sd)
    I.scaled.30.m <- apply(sapply(res.r.3, function(sub) sub[[k]]$I.scaled), 1, mean)
    I.scaled.30.s <- apply(sapply(res.r.3, function(sub) sub[[k]]$I.scaled), 1, sd)
    
    tmp.3[[k]] <- data.frame(RsqAdj.30.3.m=RsqAdj.30.m, RsqAdj.30.3.s=RsqAdj.30.s, 
                           RsqAdjPos.30.3.m=RsqAdjPos.30.m, RsqAdjPos.30.3.s=RsqAdjPos.30.s, 
                           Morans.I.30.3.m=Morans.I.30.m, Morans.I.30.3.s=Morans.I.30.s,
                           I.scaled.30.3.m=I.scaled.30.m, I.scaled.30.3.s=I.scaled.30.s)
}

tmp.500 <- list()
for(k in 1:length(res.r[[1]]))
  {
    RsqAdj.30.m <- apply(sapply(res.r.500, function(sub) sub[[k]]$RsqAdj), 1, mean)
    RsqAdj.30.s <- apply(sapply(res.r.500, function(sub) sub[[k]]$RsqAdj), 1, sd)
    RsqAdjPos.30.m <- apply(sapply(res.r.500, function(sub) sub[[k]]$RsqAdjPos), 1, mean)
    RsqAdjPos.30.s <- apply(sapply(res.r.500, function(sub) sub[[k]]$RsqAdjPos), 1, sd)
    Morans.I.30.m <- apply(sapply(res.r.500, function(sub) sub[[k]]$Morans.I), 1, mean)
    Morans.I.30.s <- apply(sapply(res.r.500, function(sub) sub[[k]]$Morans.I), 1, sd)
    I.scaled.30.m <- apply(sapply(res.r.500, function(sub) sub[[k]]$I.scaled), 1, mean)
    I.scaled.30.s <- apply(sapply(res.r.500, function(sub) sub[[k]]$I.scaled), 1, sd)
    I.scaled2.30.m <- apply(sapply(res.r.500, function(sub) sub[[k]]$I.scaled2), 1, mean)
    
    tmp.500[[k]] <- data.frame(RsqAdj.30.500.m=RsqAdj.30.m, RsqAdj.30.500.s=RsqAdj.30.s, 
                           RsqAdjPos.30.500.m=RsqAdjPos.30.m, RsqAdjPos.30.500.s=RsqAdjPos.30.s, 
                           Morans.I.30.500.m=Morans.I.30.m, Morans.I.30.500.s=Morans.I.30.s,
                           I.scaled.30.500.m=I.scaled.30.m, I.scaled.30.500.s=I.scaled.30.s)
}

res.r.combined <- Reduce(cbind, tmp)
res.r.3.combined <- Reduce(cbind, tmp.3)
res.r.500.combined <- Reduce(cbind, tmp.500)
names(res.r.combined) <- paste(rep(names(Results.subsets[[1]][[1]]), each=ncol(tmp[[1]])), 
                             names(tmp[[1]]), sep=".")
names(res.r.3.combined) <- paste(rep(names(Results.subsets[[1]][[1]]), each=ncol(tmp[[1]])), 
                             names(tmp.3[[1]]), sep=".")
names(res.r.500.combined) <- paste(rep(names(Results.subsets[[1]][[1]]), each=ncol(tmp[[1]])), 
                             names(tmp.500[[1]]), sep=".")


Results.subsets.table <- data.frame(Results.table, res.r.combined, 
                                    res.r.3.combined, res.r.500.combined)
saveRDS(Results.subsets.table, paste0(here::here(), "/output/Results.subsets.table.rds"))
Results.subsets.table
```


### c) Paired t-tests  (without IM)

Paired t-tests for difference between mean of subsamples with n = 30 and corresponding datasets with n = 90 sites.

**Interpretation:**

- All differences are highly significant.

```{r}
with(Results.subsets.table[a,], t.test(Fst.RsqAdjPos.30.m, Fst.RsqAdjPos.90, paired=TRUE))

with(Results.subsets.table[a,], t.test(Fst.Morans.I.30.m, Fst.Morans.I.90, paired=TRUE))

with(Results.subsets.table[a,], t.test(Fst.I.scaled.30.m, Fst.I.scaled.90, paired=TRUE))

with(Results.subsets.table[a,], t.test(Fst.Morans.I.30.m * 29/30, 
                                         Fst.Morans.I.90 *89/90, paired=TRUE))
with(Results.subsets.table[a,], t.test(Fst.I.scaled.30.m * 29/30,
                                         Fst.I.scaled.90*89/90, paired=TRUE))
```

### d) Effect sizes (without IM)

Cohen's d for paired t-test. This is interesting!

**Interpretation:**

- Smallest effect size for RsqAdj (when all demographic scenarios are included)

Drop IM

```{r}
with(Results.subsets.table[a,], mean(Fst.RsqAdjPos.30.m - Fst.RsqAdjPos.90)/ 
       sd(Fst.RsqAdj.30.m - Fst.RsqAdj.90))

with(Results.subsets.table[a,], mean(Fst.Morans.I.30.m - Fst.Morans.I.90)/
       sd(Fst.Morans.I.30.m - Fst.Morans.I.90)) 

with(Results.subsets.table[a,], mean(Fst.I.scaled.30.m - Fst.I.scaled.90)/
       sd(Fst.I.scaled.30.m - Fst.I.scaled.90))

with(Results.subsets.table[a,], mean(Fst.I.scaled2.30.m - Fst.I.scaled2.90)/
       sd(Fst.I.scaled2.30.m - Fst.I.scaled2.90))

with(Results.subsets.table[a,], mean(Fst.Morans.I.30.m * 29/30 - Fst.Morans.I.90 *89/90) /
       sd(Fst.Morans.I.30.m * 29/30 - Fst.Morans.I.90 *89/90))

with(Results.subsets.table[a,], mean(Fst.I.scaled.30.m * 29/30 - Fst.I.scaled.90*89/90) /
       sd(Fst.I.scaled.30.m * 29/30 - Fst.I.scaled.90*89/90))

```

## 8. Missing sites

Simulations to compare results between full sample and sample with some missing sites. Two possible methods:

- Redo MEMgene (including MEM) for each dataset, based on available sites
- Keep MEM, do adj R2 based on positive MEM, which avoids overfitting

### a) Leave X sites out at a time

Run function in parallel:

```{r MEMgeneDrop}
start_time <- Sys.time()

Index.j <- 1:length(Sites.R.90)
R = 10
Results.drop <- rep( list(list()), R)

set.seed(297)
Drop <-lapply(c(1:R), function(r) sort(sample(1:90, 30)))

for(r in 1:R)
{
  cat(r)
  Results.drop[[r]] <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90,
                                                       subset=NULL, drop=Drop[[r]]),
                                mc.cores=detectCores())
  names(Results.drop[[r]]) <- Sites.R.90
}

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.drop, paste0(here::here(), "/output/Results.drop.rds"))
```

Repeat with refitting MEM

```{r MEMgeneDrop}
start_time <- Sys.time()

Index.j <- 1:length(Sites.R.90)
R = 10
Results.drop.MEM <- rep( list(list()), R)

for(r in 1:R)
{
  cat(r)
  Results.drop.MEM[[r]] <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90,
                                                       subset=c(1:90)[-Drop[[r]]], drop=NULL),
                                mc.cores=detectCores())
  names(Results.drop.MEM[[r]]) <- Sites.R.90
}

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.drop.MEM, paste0(here::here(), "/output/Results.drop.MEM.rds"))
```

### b) Compile results with dropped sites

Determine mean and sdev among the R = 10 replicate subsets for each dataset with 5 sites dropped

```{r}
Results.drop <- readRDS(paste0(here::here(), "/output/Results.drop.rds"))
Results.subsets.table <-  readRDS(paste0(here::here(), "/output/Results.subsets.table.rds"))
```


```{r}
res.r <- lapply(Results.drop, function(sub) 
  lapply(c(1:length(Results.drop[[1]][[1]])), function(k) getRes(sub, k)))

tmp <- list()
for(k in 1:length(res.r[[1]]))
  {
    S.tot.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$S.tot), 1, mean)
    S.tot.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$S.tot), 1, sd)
    RsqAdjPos.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdjPos), 1, mean)
    RsqAdjPos.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdjPos), 1, sd)
    Morans.I.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$Morans.I), 1, mean)
    Morans.I.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$Morans.I), 1, sd)
    I.scaled.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled), 1, mean)
    I.scaled.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled), 1, sd)
  
    tmp[[k]] <- data.frame(S.tot.drop.m=S.tot.drop.m, S.tot.drop.s=S.tot.drop.s,
                           RsqAdjPos.drop.m=RsqAdjPos.drop.m, RsqAdjPos.drop.s=RsqAdjPos.drop.s, 
                           Morans.I.drop.m=Morans.I.drop.m, Morans.I.drop.s=Morans.I.drop.s,
                           I.scaled.drop.m=I.scaled.drop.m, I.scaled.drop.s=I.scaled.drop.s)
}

res.r.combined <- Reduce(cbind, tmp)

names(res.r.combined) <- paste(rep(names(Results.drop[[1]][[1]]), each=ncol(tmp[[1]])), 
                             names(tmp[[1]]), sep=".")

Results.drop.table <- data.frame(Results.subsets.table, res.r.combined)
saveRDS(Results.drop.table, paste0(here::here(), "/output/Results.drop.table.rds"))
Results.drop.table
```

Determine mean and sdev among the R = 10 replicate subsets for each dataset

```{r}
Results.drop.MEM <- readRDS(paste0(here::here(), "/output/Results.drop.MEM.rds"))
Results.drop.table <-  readRDS(paste0(here::here(), "/output/Results.drop.table.rds"))
```

Repeat with refitted MEM

```{r}
res.r <- lapply(Results.drop.MEM, function(sub) 
  lapply(c(1:length(Results.drop[[1]][[1]])), function(k) getRes(sub, k)))

tmp <- list()
for(k in 1:length(res.r[[1]]))
  {
    S.tot.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$S.tot), 1, mean)
    S.tot.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$S.tot), 1, sd)
    RsqAdjPos.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdjPos), 1, mean)
    RsqAdjPos.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdjPos), 1, sd)
    Morans.I.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$Morans.I), 1, mean)
    Morans.I.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$Morans.I), 1, sd)
    I.scaled.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled), 1, mean)
    I.scaled.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled), 1, sd)
  
    tmp[[k]] <- data.frame(S.tot.drop.MEM.m=S.tot.drop.m, S.tot.drop.MEM.s=S.tot.drop.s,
                           RsqAdjPos.drop.MEM.m=RsqAdjPos.drop.m, RsqAdjPos.drop.MEM.s=RsqAdjPos.drop.s, 
                           Morans.I.drop.MEM.m=Morans.I.drop.m, Morans.I.drop.MEM.s=Morans.I.drop.s,
                           I.scaled.drop.MEM.m=I.scaled.drop.m, I.scaled.drop.MEM.s=I.scaled.drop.s)
}

res.r.combined <- Reduce(cbind, tmp)

names(res.r.combined) <- paste(rep(names(Results.drop[[1]][[1]]), each=ncol(tmp[[1]])), 
                             names(tmp[[1]]), sep=".")

Results.drop.MEM.table <- data.frame(Results.drop.table, res.r.combined)
saveRDS(Results.drop.MEM.table, paste0(here::here(), "/output/Results.drop.MEM.table.rds"))
Results.drop.MEM.table
```


 Statistical tests
 
```{r}
with(Results.drop5.table %>% filter(Demography == "1R"), 
     t.test(Fst.RsqAdjPos.drop.m, Fst.RsqAdjPos.90, paired=TRUE))

with(Results.drop5.table %>% filter(Demography == "2R"), 
     t.test(Fst.RsqAdjPos.drop.m, Fst.RsqAdjPos.90, paired=TRUE))

with(Results.drop5.table %>% filter(Demography == "IBD"), 
     t.test(Fst.RsqAdjPos.drop.m, Fst.RsqAdjPos.90, paired=TRUE))

with(Results.drop5.table %>% filter(Demography == "1R"), 
     t.test(Fst.Morans.I.drop.m, Fst.Morans.I.90, paired=TRUE))

with(Results.drop5.table %>% filter(Demography == "2R"), 
     t.test(Fst.Morans.I.drop.m, Fst.Morans.I.90, paired=TRUE))

with(Results.drop5.table %>% filter(Demography == "IBD"), 
     t.test(Fst.Morans.I.drop.m, Fst.Morans.I.90, paired=TRUE))
```
 
 Effect sizes:
 
```{r}
Diff <- with(Results.drop5.table %>% filter(Demography == "1R"), 
     Fst.RsqAdjPos.drop.m - Fst.RsqAdjPos.90)
mean(Diff) / sd(Diff)

Diff <- with(Results.drop5.table %>% filter(Demography == "2R"), 
     Fst.RsqAdjPos.drop.m - Fst.RsqAdjPos.90)
mean(Diff) / sd(Diff)

Diff <- with(Results.drop5.table %>% filter(Demography == "IBD"), 
     Fst.RsqAdjPos.drop.m - Fst.RsqAdjPos.90)
mean(Diff) / sd(Diff)

Diff <- with(Results.drop5.table %>% filter(Demography == "1R"), 
     Fst.Morans.I.drop.m - Fst.Morans.I.90)
mean(Diff) / sd(Diff)

Diff <- with(Results.drop5.table %>% filter(Demography == "2R"), 
     Fst.Morans.I.drop.m - Fst.Morans.I.90)
mean(Diff) / sd(Diff)

Diff <- with(Results.drop5.table %>% filter(Demography == "IBD"), 
     Fst.Morans.I.drop.m - Fst.Morans.I.90)
mean(Diff) / sd(Diff)
```
 


```{r}
#Results.drop5.table <- readRDS(paste0(here::here(), "/output/Results.drop5.table.rds"))
```

