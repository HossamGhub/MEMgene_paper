---
title: "MEMgene paper analysis"
output: 
  html_document:
    theme: flatly
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
      smooth_scroll: false
---

Analysis of simulated datasets from Lotterhos & Whitlock with the same random sampling of 90 sites as in Wagner et al. (2017).

Goal:

Design:

Genetic data:

Response variables:


## 1. Preparations

### a) Packages

```{r packages}
#library(adegenet)
library(hierfstat)
#library(spdep)
#library(adespatial)
library(memgene)
library(here)
library(parallel)
library(dplyr)
library(spdep)
```

### b) Import patial coordinates

```{r coords}
Coords <- list()
Coords$Pairs <- list()
# Coords$Pairs$E453 <- read.table("1351142954_453EnviMatPAIRS_ED.txt")
# Coords$Pairs$E988 <- read.table("1351142970_988EnviMatPAIRS_ED.txt")
# Coords$Pairs$E950 <- read.table("1351142986_950EnviMatPAIRS_ED.txt")
Coords$Transect <- list()
# Coords$Transect$E453 <- read.table("1351142954_453EnviMatTRANSECTS_ED_Design.txt")
# Coords$Transect$E988 <- read.table("1351142970_988EnviMatTRANSECTS_ED_Design.txt")
# Coords$Transect$E950 <- read.table("1351142986_950EnviMatTRANSECTS_ED_Design.txt")
Coords$Random <- list()
Coords$Random$E453 <- Coords$Random$E988 <- Coords$Random$E950 <- 
  read.table("SchemeRandom1.txt") # upload this file

# for(k in 1:length(Coords$Transect))
# {
#   names(Coords$Transect[[k]])[2:3] <- names(Coords$Pairs[[1]])[2:3]
#   Coords$Transect[[k]][,7:9][is.na(Coords$Transect[[k]][,7:9])] <- FALSE
# }
for(i in 1:length(Coords))
{
  if(length(Coords[[i]]) > 0)
  {
    for(k in 1:length(Coords[[i]]))
    {
      b <- order(Coords[[i]][[k]][,3], Coords[[i]][[k]][,2]) # Sort by y, then x
      Coords[[i]][[k]] <- Coords[[i]][[k]][b,]  # correct order!!
    }
  }
  
}
```

### c) Parameter space

Genetic data: find all file names in the folder "SimFilesLFMM" that contain 'lfmm':

```{r files}
Filenames.lfmm <- list.files(paste0(here::here(), "/dryad//SimFilesLFMM/"), pattern="lfmm") 

test <- Reduce(rbind, strsplit(Filenames.lfmm, split="[_=]"))
test <- cbind(test, Reduce(rbind, strsplit(test[,ncol(test)], split="[.]")))
tmp <- strsplit(test[,2], split="[.xs]")
test2 <- matrix(NA, nrow(test), 3)
for(i in 1:nrow(test)) test2[i,1:length(tmp[[i]])] <- tmp[[i]]
test2 <- gsub("[A-Z, a-z]","", test2)
test <- cbind(test, test2)
dimnames(test) <- list(NULL, c("Demography", "Design", "ID", "Env", "ID2", 
                               "V6", "NumPops", "V8", "V9", "NumInd", "Design2",
                               "NumPops2", "NumTrans", "NumInd2"))
```

Design matrix (parameter space): each row is one combination of parameter settings:

- Demography: single refugium (1R), two refugia (2R), isolation by distane (IBD), island model (IM)
- Design: sampling design (R, P, T; see below) and number of pops sampled
- Env: which of the three replicate landscapes '453', '950', '988'
- NumPops: how many populations are sampled
- NumInd: how many individuals sampled per pop
- Type: random (R), pairs (P), transects (T)

```{r Design}   
   Design <- as.data.frame(test[,c(1,2,4,7,10,13,14)])
   Design$Env <- ordered(Design$Env, levels=c(453,988,950))
   Design$Type <- ordered(substr(Design$Design, 1, 1), levels=c("P", "T", "R"))
   Design$Design <- as.character(Design$Design)
   Design$Design[Design$Design == "T30.T3x10"] <- "T30.3x10s"
   Design$Design[Design$Design == "T30.T6x5s"] <- "T30.6x5s"
   Design$NumPops <- as.numeric(as.character(Design$NumPops))
   head(Design)
```

### d) Create R replicate random samples of n = 30 sites

```{r subsets}
R = 10
Sites.30 <- list()
for(r in 1:R)
{
  Sites.30[[r]] <- sort(sample(1:90, 30, replace=FALSE))
}

# Alternative: split into quadrants
# ---------------------------------
# R = 4
# GroupX <- rep("A", 90)
# GroupX[coord[,1] < median(coord[,1])] <- "B"
# GroupY <- rep("C", 90)
# GroupY[coord[,2] <= median(coord[,2])] <- "D"
# Group <- factor(paste0(GroupX, GroupY))
# Sites.30 <- split(c(1:90), Group)


saveRDS(Sites.30, paste0(here::here(), "/output/Sites.30.rds"))
```


## 2. Genetic data

### a) Select datasets

Select all data files with the largest sample size (90) and random sampling (R)

```{r}
Sites.R.90 <- c(1:nrow(Design))[Design$NumPops==90 & Design$Type=="R"] 
```

Check parameters for selected datasets:

```{r}
Design[Sites.R.90,]
```

### b) Run function 'getGenData' to extract the genetic data

This function extracts the genetic data, selects the 9900 neutral loci, and adds a first column 'pop' with site as a factor. This is the format for functions in the package `hierfstat`.

Define function:

```{r getGenData}
getGenData <- function(j)
{
  # Select the sites that need to be sampled for this run:
  i=Sites.R.90[j]
  cat("j:", j, ", i:", i, "\n")
  
  # Each file has NumPops x NumInd rows (sampled individuals) and up to 10000 columns (loci)
  tmp <- read.table(paste0(here::here(),"/dryad/SimFilesLFMM/", Filenames.lfmm[[i]]))
  
  # Drop non-neutral loci
  tmp <- tmp[,1:9900]
    
  # Site: create vector of sites = pops (for each row = individual)
  Site <- rep(1:Design$NumPops[i],each=as.numeric(as.vector(Design$NumInd)[i]))
  
  #Data.hierfstat <- data.frame(pop=factor(Site), tmp)
  Data.hierfstat <- data.frame(pop=Site, tmp)
  
  return(Data.hierfstat)
}
```

Run in parallel and save results:

```{r GenData90}
start_time <- Sys.time()

Index.j <- 1:length(Sites.R.90)

Data.R.90 <- mclapply(Index.j, function(j) getGenData(j),
                 mc.cores=detectCores())
names(Data.R.90) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Data.R.90, paste0(here::here(), "/output/Data.R.90.rds"))
```

Results are stored in a list (one element per site j with 90 samples), with each element:

- Data.frame with first column "pop" (factor of site IDs) and 9900 columns of neutral loci
    
### c) Run function 'getDgen' to calculate sample Fst and genetic distances

Define function:

```{r getDgen}
#Data.R.90 <- readRDS(paste0(here::here(), "/output/Data.R.90.rds"))

getDgen <- function(j, Data=Data.R.90, dist.method = c("Fst", "Dch"), nLoci=9900)
{
  Fst <- basic.stats(Data[[j]][,1:(nLoci+1)])$overall

  Fst.30 <- t(sapply(1:length(Sites.30), function(s) 
    basic.stats(filter(Data[[j]][, 1:(nLoci+1)], is.element(pop, Sites.30[[s]])))$overall))
  
  D <- list()
  for(k in 1:length(dist.method))
  {
    D[[k]] <- genet.dist(Data[[j]][,1:(nLoci+1)], method = dist.method[k])
  }
  names(D) <- dist.method
  
  return(list(Fst=Fst, Fst.30 = Fst.30, Dgen=D))
}
```

Run in parallel and save results: (this takes a longer time: 10.4 min on Helene's iMac)

```{r Dgen90}
start_time <- Sys.time()

Index.j <- 1:length(Sites.R.90)

Dgen.R.90 <- mclapply(Index.j, function(j) getDgen(j, Data=Data.R.90, nLoci=9900, 
                                                 dist.method=c("Fst", "Dch")),
                 mc.cores=detectCores())
names(Dgen.R.90) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Dgen.R.90, paste0(here::here(), "/output/Dgen.R.90.rds"))
```

Repeat for first 3300 loci

(Note: no effect of locus number on variability, i.e., first 3300 can be considered a random sample as much as any other subset of 3300)

```{r Dgen90.3}
start_time <- Sys.time()

Index.j <- 1:length(Sites.R.90)

Dgen.R.90.3 <- mclapply(Index.j, function(j) getDgen(j, Data=Data.R.90, nLoci=3300,
                                                 dist.method=c("Fst", "Dch")),
                 mc.cores=detectCores())
names(Dgen.R.90.3) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Dgen.R.90.3, paste0(here::here(), "/output/Dgen.R.90.3.rds"))
```

Repeat for 500 loci

```{r Dgen90.500}
start_time <- Sys.time()

Index.j <- 1:length(Sites.R.90)

Dgen.R.90.500 <- mclapply(Index.j, function(j) getDgen(j, Data=Data.R.90, nLoci=500,
                                                 dist.method=c("Fst", "Dch")),
                 mc.cores=detectCores())
names(Dgen.R.90.500) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Dgen.R.90.500, paste0(here::here(), "/output/Dgen.R.90.500.rds"))
```

Results are stored in a list (one element per site j with 90 samples) with these elements:

- Fst: vector with 'overall' statistics returned by `basic.stats` function
- Fst.30: matrix with statistics for ten subsets of n = 30 sites
- Dgen: list of pairwise genetic distance matrices
    - Fst (Fst)
    - Cavalli-Sforza and Edwards Chord distance (Dch)

### d) Run function 'getMEMgene' to obtain RsqAdj and Moran's I

This function extracts the grid coordinates, performs memgene analysis with forward selection to obtain the adjusted Rsquare. It also calculates Moran's I for the genetic data by obtaining a scalogram S (Rsquare for each MEM vector, which sum to 1 across all MEM vectors) and multiplying with the rescaled MEM eigenvectors (Moran's I for each vector). It also returns the limits for Moran's I of the genetic data (min and max of Moran's I values of MEM vectors).

Argument 'subset' specifies a subset of sites to be used (for samples with n = 30). Argument 'drop' specifies which sites should be dropped (for simulating missing sites).

Define function:

```{r getMEMgene}
getMEMgene <- function(j, Dgen = Dgen.R.90, subset=NULL, drop=NULL)
{
  i=Sites.R.90[j]
  cat("j:", j, ", i:", i, "\n")
  
  # Extract the grid coordinates of the sampled sites
  coord <- data.matrix(Coords[[as.numeric(Design$Type[i])]]
                     [[as.numeric(Design$Env[i])]][,2:3])
  if(length(subset) > 0)
  {
     coord <- coord[subset,]
  }
  
  if(length(drop) > 0) { coord.drop <- coord[-drop,]}
  
  Res <- list()
  for(k in 1: length(Dgen[[j]]$Dgen))
  {
    
    Y <- as.matrix(Dgen[[j]]$Dgen[[k]])
    if(length(drop) > 0) {Y = Y[-drop, -drop]}
    
    if(length(subset) > 0)
    {
       Y <- Y[subset, subset]
    }
    
    # memGene
    
    MEM <- mgMEM(dist(coord))
    
    if(length(drop) > 0) 
    {
      MEM$vectorsMEM <- MEM$vectorsMEM[-drop,]
    }

    Positive <- mgForward(Y, MEM$vectorsMEM[, MEM$valuesMEM > 0])
    #Negative <- mgForward(Y,MEM$vectorsMEM[ -drop, MEM$valuesMEM < 0])
    #allSelected <- cbind(MEM$vectorsMEM[-drop, MEM$valuesMEM > 0][,na.omit(Positive$selectedMEM)],
    #                  MEM$vectorsMEM[-drop, MEM$valuesMEM < 0][,na.omit(Negative$selectedMEM)])
    RsqAdjPos = 0
    if(!is.na(Positive$selectedRsqAdj)) { RsqAdjPos = Positive$selectedRsqAdj}
    
    # if(ncol(allSelected) > 0)
    # {
    #    MEM$analysis <- mgRDA(Y, allSelected, full=TRUE)
    #    RsqAdj <- MEM$analysis$RsqAd
    #    Rsq <- sum(diag(MEM$analysis$pred)) / (sum(diag(MEM$analysis$pred)) +
    #                                           sum(diag(MEM$analysis$resid)))
    #    if(length(Positive$selectedMEM) > 0) 
    #    {
    #      RsqAdjPos <- mgRDA(Y, allSelected[,1:length(Positive$selectedMEM)], full=TRUE)$RsqAd
    #    }
    # }
    
    if(length(drop) > 0)
    {
      MEM.drop <- mgMEM(dist(coord.drop))
      
      Positive <- mgForward(Y, MEM.drop$vectorsMEM[ , MEM.drop$valuesMEM > 0])
      RsqAdjPos.drop = 0
      if(!is.na(Positive$selectedRsqAdj)) { RsqAdjPos.drop = Positive$selectedRsqAdj}
    }

    # Centre distance matrix
    n <- nrow(Y)
    row.wt = rep(1, nrow(Y))
    col.wt = rep(1, ncol(Y))
    st <- sum(col.wt)
    sr <- sum(row.wt)
    row.wt <- row.wt/sr
    col.wt <- col.wt/st
    Y <- -0.5 * (Y * Y)
    row.mean <- apply(row.wt * Y, 2, sum)
    col.mean <- apply(col.wt * t(Y), 2, sum)
    col.mean <- col.mean - sum(row.mean * col.wt)
    Y <- sweep(Y, 2, row.mean)
    G <- t(sweep(t(Y), 2, col.mean))
    
    # Get Rsq for each MEM vector from a separate dbRDA for each vector m
    X <- MEM$vectorsMEM
  
    S <- rep(0, ncol(X))
    for(m in 1:ncol(X))
    {
      if(var(X[,m]) > 0)
      {
        p = 1
        H <- X[,m] %*% solve(t(X[,m]) %*% X[,m]) %*% t(X[,m])
        I <- diag(n)
        res <- (I - H) %*% G %*% (I - H)
        S[m] <- 1 - sum(diag(res))/sum(diag(G))
      }
    }
    
    #HW: check why these corrections are needed sometimes?
    #    Dropped correction due to issues with 'drop5' data
    S.tot = sum(S)
    S.min = min(S)
    S[S < 0] <- 0
    #S = S / sum(S)
    
    #tmp <- mgW.HW(dist(coord))
    #if(length(drop) > 0) tmp <- mgW.HW(dist(coord.drop))
    
    # Get Moran's I
    Values <- MEM$valuesMEM / abs(sum(MEM$valuesMEM))
    Range <- range(Values)
    Morans.I <- as.vector(S %*% Values)
    #I.sd <- ape::Moran.I(rnorm(n), tmp)$sd
    C <- diag(t(sqrt(S)) %*% diag(Values^2) %*% sqrt(S))
    Rho <- Morans.I / sqrt(C)
    
    # if(length(drop) > 0)
    # {
    #   X <- MEM.drop$vectorsMEM
    # 
    #   S <- rep(0, ncol(X))
    #   for(m in 1:ncol(X))
    #   {
    #     if(var(X[,m]) > 0)
    #     {
    #       p = 1
    #       H <- X[,m] %*% solve(t(X[,m]) %*% X[,m]) %*% t(X[,m])
    #       I <- diag(n)
    #       res <- (I - H) %*% G %*% (I - H)
    #       S[m] <- 1 - sum(diag(res))/sum(diag(G))
    #     }
    #   }
    #   
    #   S.tot.drop = sum(S)
    #   S[S < 0] <- 0
    #   #S = S / sum(S)
    # 
    #   #tmp <- mgW.HW(dist(coord.drop))
    # 
    #   # Get Moran's I
    #   Values <- MEM.drop$valuesMEM / abs(sum(MEM.drop$valuesMEM))
    #   Range.drop <- range(Values)
    #   Morans.I.drop <- as.vector(S %*% Values)
    #   #I.sd.drop <- ape::Moran.I(rnorm(n), tmp)$sd
    #   C.drop <- diag(t(sqrt(S)) %*% diag(Values^2) %*% sqrt(S))
    #   Rho.drop <- Morans.I.drop / sqrt(C.drop)
    # }
    
    Res[[k]] <- list(RsqAdjPos=RsqAdjPos, Morans.I=Morans.I, C=C, Rho=Rho, Range=Range, S.tot=S.tot, S.min=S.min)
    
    # if(length(drop) > 0)
    # {
    #   Res[[k]] <- list(RsqAdjPos=RsqAdjPos, Morans.I=Morans.I, C=C, Rho=Rho, Range=Range,
    #                    RsqAdjPos.drop=RsqAdjPos.drop, Morans.I.drop=Morans.I.drop, 
    #                    C.drop=C.drop, Rho.drop=Rho.drop, Range.drop=Range.drop, 
    #                    S.tot=S.tot, S.min=S.min, S.tot.drop=S.tot.drop)
    # }
  }
  names(Res) <- names(Dgen[[1]]$Dgen)
  
  return(Res)
}
```

Run function in parallel:

```{r MEMgene90}
#Dgen.R.90 <- readRDS(paste0(here::here(), "/output/Dgen.R.90.rds"))

start_time <- Sys.time() 

Index.j <- 1:length(Sites.R.90)

Results.R.90 <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90, subset=NULL),
                    mc.cores=detectCores())
names(Results.R.90) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.R.90, paste0(here::here(), "/output/Results.R.90.rds"))
```

Repeat for 3300 loci

```{r MEMgene90.3}
#Dgen.R.90.3 <- readRDS(paste0(here::here(), "/output/Dgen.R.90.3.rds"))

start_time <- Sys.time() 

Index.j <- 1:length(Sites.R.90)

Results.R.90.3 <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90.3, subset=NULL),
                    mc.cores=detectCores())
names(Results.R.90.3) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.R.90.3, paste0(here::here(), "/output/Results.R.90.3.rds"))
```

Repeat for 500 loci

```{r MEMgene90.500}
start_time <- Sys.time() 

Index.j <- 1:length(Sites.R.90)

Results.R.90.500 <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90.500, subset=NULL),
                    mc.cores=detectCores())
names(Results.R.90.500) <- Sites.R.90

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.R.90.500, paste0(here::here(), "/output/Results.R.90.500.rds"))
```

Results are stored in a list (one element per site j with 90 samples) with these elements:

- List with one element per genetic distance measure:
  - RsqAdj: adjusted Rsquare from default analysis with memgene
  - Rsq: unadjusted Rsquare from default analysis with memgene
  - Morans.I: Moran's I for the genetic data
  - Range: range (minimum and maximum) of Moran's I of MEM vectors (limits for Moran's I of genetic data)

  
## 3. Compile results for n = 90

Import results without overwriting:

```{r}
Results <- readRDS(paste0(here::here(), "/output/Results.R.90.rds"))
Results.3 <- readRDS(paste0(here::here(), "/output/Results.R.90.3.rds"))
Results.500 <- readRDS(paste0(here::here(), "/output/Results.R.90.500.rds"))

D <- readRDS(paste0(here::here(), "/output/Dgen.R.90.rds"))
D.3 <- readRDS(paste0(here::here(), "/output/Dgen.R.90.3.rds"))
D.500 <- readRDS(paste0(here::here(), "/output/Dgen.R.90.500.rds"))
```

Function to extract response variables

```{r}
# getRes <- function(Results=Results, k = 1)
# {
#   RsqAdj = sapply(Results, function(ls) ls[[k]]$RsqAdj)
#   RsqAdjPos = sapply(Results, function(ls) ls[[k]]$RsqAdjPos)
#   Rsq = sapply(Results, function(ls) ls[[k]]$Rsq)
#   Morans.I = sapply(Results, function(ls) ls[[k]]$Morans.I)
#   C = sapply(Results, function(ls) ls[[k]]$C)
#   Rho = sapply(Results, function(ls) ls[[k]]$Rho)
#   I.max = sapply(Results, function(ls) max(ls[[k]]$Range))
#   I.min = sapply(Results, function(ls) min(ls[[k]]$Range))
#   I.sd = sapply(Results, function(ls) ls[[k]]$I.sd)
#   I.scaled = Morans.I / I.max
#   I.scaled2 = 2 * (Morans.I - I.min)/(I.max - I.min) - 1
#   I.z = Morans.I / I.sd
#   res <- data.frame(RsqAdj=RsqAdj, RsqAdjPos=RsqAdjPos, Rsq=Rsq, Morans.I=Morans.I, C=C, Rho=Rho,
#                     I.max=I.max, I.min=I.min, I.scaled=I.scaled, I.scaled2=I.scaled2, I.z=I.z)
# }
```

Note: revised function!
```{r}
getRes <- function(Results=Results, k = 1)
{
  #RsqAdj = sapply(Results, function(ls) ls[[k]]$RsqAdj)
  S.tot = sapply(Results, function(ls) ls[[k]]$S.tot)
  S.min = sapply(Results, function(ls) ls[[k]]$S.min)
  RsqAdjPos = sapply(Results, function(ls) ls[[k]]$RsqAdjPos)
  #Rsq = sapply(Results, function(ls) ls[[k]]$Rsq)
  Morans.I = sapply(Results, function(ls) ls[[k]]$Morans.I)
  C = sapply(Results, function(ls) ls[[k]]$C)
  Rho = sapply(Results, function(ls) ls[[k]]$Rho)
  I.max = sapply(Results, function(ls) max(ls[[k]]$Range))
  I.min = sapply(Results, function(ls) min(ls[[k]]$Range))
  #I.sd = sapply(Results, function(ls) ls[[k]]$I.sd)
  I.scaled = Morans.I / I.max
  I.scaled2 = 2 * (Morans.I - I.min)/(I.max - I.min) - 1
  #I.z = Morans.I / I.sd
  #res <- data.frame(RsqAdj=RsqAdj, RsqAdjPos=RsqAdjPos, Rsq=Rsq, Morans.I=Morans.I, C=C, Rho=Rho,
  #                  I.max=I.max, I.min=I.min, I.scaled=I.scaled, I.scaled2=I.scaled2, I.z=I.z)
  res <- data.frame(S.tot=S.tot, S.min=S.min, RsqAdjPos=RsqAdjPos, Morans.I=Morans.I, C=C, Rho=Rho,
                    I.max=I.max, I.min=I.min, I.scaled=I.scaled, I.scaled2=I.scaled2)
}
```


Combine response variables with Design matrix

```{r}
Ftab <- data.frame(Fst.90 = sapply(D, function(ls) ls$Fst[7]),
                   Fst.30.m = sapply(D, function(ls) mean(ls$Fst.30[,7])),
                   Fst.30.s = sapply(D, function(ls) sd(ls$Fst.30[,7])),
                   Fst.90.3 = sapply(D.3, function(ls) ls$Fst[7]),
                   Fst.30.m.3 = sapply(D.3, function(ls) mean(ls$Fst.30[,7])),
                   Fst.30.s.3 = sapply(D.3, function(ls) sd(ls$Fst.30[,7])),
                   Fst.90.500 = sapply(D.500, function(ls) ls$Fst[7]),
                   Fst.30.m.500 = sapply(D.500, function(ls) mean(ls$Fst.30[,7])),
                   Fst.30.s.500 = sapply(D.500, function(ls) sd(ls$Fst.30[,7])))

res <- lapply(c(1:length(Results[[1]])), function(k) getRes(Results, k))
res.3 <- lapply(c(1:length(Results.3[[1]])), function(k) getRes(Results.3, k))
res.500 <- lapply(c(1:length(Results.500[[1]])), function(k) getRes(Results.500, k))
names(res) <- names(res.3) <-names(res.500) <-names(Results[[1]])

res.combined <- Reduce(cbind, res)
res.3.combined <- Reduce(cbind, res.3)
res.500.combined <- Reduce(cbind, res.500)
names(res.combined) <- paste(rep(names(Results[[1]]), each=ncol(res[[1]])), 
                             names(res[[1]]), "90", sep=".")
names(res.3.combined) <- paste(names(res.combined), "3", sep=".")
names(res.500.combined) <- paste(names(res.combined), "500", sep=".")

Results.table <- data.frame(Design[Sites.R.90,], Ftab, res.combined, 
                            res.3.combined, res.500.combined)
saveRDS(Results.table, paste0(here::here(), "/output/Results.table.rds"))
Results.table

rm(list=c("Results", "Results.3", "Results.500", "D", "D.3", "D.500"))
```


Analyze according to the following factors:

- Demography (1R, 2R, IBD, IM)
- NumInd: 20, 6
- Genetic distance measure (Fst, Dch)
- Number of loci (9900 or 3300) (where variable names with .3 denote 3300 loci)

Response variables:

- RsqAdj: based on all MEM selected
- RsqAdjPos: as RsquAdj in memgene output with default settings (only positive MEM)
- Rsq: unadjusted (not reported in memgene)
- Morans.I: assuming population is sampled. Correct with (n-1)/n (where n = 90) for estimating population Moran's I
- Morans.I.scaled: this is experimental. Divide Morans.I by the maximum value (max(Range)).
- Morans.I.scaled2: this is experimental. Rescaled to range between [-1, 1]: `I.scaled2 = 2 * (I - min)/(max - min) - 1`

Notes:

- Env: for each combination, there are three replicate datasets (Env: 453, 988, 950). Env could be used as a blocking variable.


## 4. Analyze data for subsets with 30 pops

### a) Repeat MEMgene with n = 30

The R = 10 subsets of n = 30 sites for each dataset with n = 90 sites were defined above already in object `Sites.30`.

```{r MEMgene30}
start_time <- Sys.time()

Index.j <- 1:length(Sites.R.90)
R = length(Sites.30)
Results.R.30 <- rep( list(list()), R)

for(r in 1:R)
{
  Results.R.30[[r]] <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90,
                                                       subset=Sites.30[[r]]),
                                mc.cores=detectCores())
  names(Results.R.30[[r]]) <- Sites.R.90
}

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.R.30, paste0(here::here(), "/output/Results.R.30.rds"))
```

Repeat for 3300 loci

```{r MEMgene30.3}
start_time <- Sys.time()

Results.R.30.3 <- rep( list(list()), R)

for(r in 1:R)
{
  Results.R.30.3[[r]] <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90.3,
                                                       subset=Sites.30[[r]]),
                                mc.cores=detectCores())
  names(Results.R.30.3[[r]]) <- Sites.R.90
}

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.R.30.3, paste0(here::here(), "/output/Results.R.30.3.rds"))
```

Repeat for 500 loci

```{r MEMgene30.500}
start_time <- Sys.time()

Results.R.30.500 <- rep( list(list()), R)

for(r in 1:R)
{
  Results.R.30.500[[r]] <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90.500,
                                                       subset=Sites.30[[r]]),
                                mc.cores=detectCores())
  names(Results.R.30.500[[r]]) <- Sites.R.90
}

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.R.30.500, paste0(here::here(), "/output/Results.R.30.500.rds"))
```

### b) Compile results for n = 30

Determine mean and sdev among the R = 10 replicate subsets for each datasest with 90 pops.

Import results without overwriting:

```{r}
Results.subsets <- readRDS(paste0(here::here(), "/output/Results.R.30.rds"))
Results.3.subsets <- readRDS(paste0(here::here(), "/output/Results.R.30.3.rds"))
Results.500.subsets <- readRDS(paste0(here::here(), "/output/Results.R.30.500.rds"))
```

Combine mean and sdev of response variables with Design matrix:

Note: dropped Rsq due to errors when knitting.

```{r}
res.r <- lapply(Results.subsets, function(sub) 
  lapply(c(1:length(Results.subsets[[1]][[1]])), function(k) getRes(sub, k)))
res.r.3 <- lapply(Results.3.subsets, function(sub) 
  lapply(c(1:length(Results.3.subsets[[1]][[1]])), function(k) getRes(sub, k)))
res.r.500 <- lapply(Results.500.subsets, function(sub) 
  lapply(c(1:length(Results.500.subsets[[1]][[1]])), function(k) getRes(sub, k)))

tmp <- list()
for(k in 1:length(res.r[[1]]))
  {
    RsqAdj.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdj), 1, mean)
    RsqAdj.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdj), 1, sd)
    RsqAdjPos.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdjPos), 1, mean)
    RsqAdjPos.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdjPos), 1, sd)
    Morans.I.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$Morans.I), 1, mean)
    Morans.I.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$Morans.I), 1, sd)
    C.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$C), 1, mean)
    C.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$C), 1, sd)
    Rho.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$Rho), 1, mean)
    Rho.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$Rho), 1, sd)
    I.scaled.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled), 1, mean)
    I.scaled.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled), 1, sd)
    I.scaled2.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled2), 1, mean)
    I.scaled2.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled2), 1, sd)
    I.z.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$I.z), 1, mean)
    I.z.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$I.z), 1, sd)
  
    tmp[[k]] <- data.frame(RsqAdj.30.m=RsqAdj.30.m, RsqAdj.30.s=RsqAdj.30.s, 
                           RsqAdjPos.30.m=RsqAdjPos.30.m, RsqAdjPos.30.s=RsqAdjPos.30.s, 
                           Morans.I.30.m=Morans.I.30.m, Morans.I.30.s=Morans.I.30.s,
                           C.30.m=C.30.m, C.30.s=C.30.s, Rho.30.m=Rho.30.m, Rho.30.s=Rho.30.s,
                           I.scaled.30.m=I.scaled.30.m, I.scaled.30.s=I.scaled.30.s,
                           I.scaled2.30.m=I.scaled2.30.m, I.scaled2.30.s=I.scaled2.30.s,
                           I.z.30.m=I.z.30.m, I.z.30.s=I.z.30.s)
}

tmp.3 <- list()
for(k in 1:length(res.r[[1]]))
  {
    RsqAdj.30.m <- apply(sapply(res.r.3, function(sub) sub[[k]]$RsqAdj), 1, mean)
    RsqAdj.30.s <- apply(sapply(res.r.3, function(sub) sub[[k]]$RsqAdj), 1, sd)
    RsqAdjPos.30.m <- apply(sapply(res.r.3, function(sub) sub[[k]]$RsqAdjPos), 1, mean)
    RsqAdjPos.30.s <- apply(sapply(res.r.3, function(sub) sub[[k]]$RsqAdjPos), 1, sd)
    Morans.I.30.m <- apply(sapply(res.r.3, function(sub) sub[[k]]$Morans.I), 1, mean)
    Morans.I.30.s <- apply(sapply(res.r.3, function(sub) sub[[k]]$Morans.I), 1, sd)
    C.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$C), 1, mean)
    C.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$C), 1, sd)
    Rho.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$Rho), 1, mean)
    Rho.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$Rho), 1, sd)
    I.scaled.30.m <- apply(sapply(res.r.3, function(sub) sub[[k]]$I.scaled), 1, mean)
    I.scaled.30.s <- apply(sapply(res.r.3, function(sub) sub[[k]]$I.scaled), 1, sd)
    I.scaled2.30.m <- apply(sapply(res.r.3, function(sub) sub[[k]]$I.scaled2), 1, mean)
    I.scaled2.30.s <- apply(sapply(res.r.3, function(sub) sub[[k]]$I.scaled2), 1, sd)
    I.z.30.m <- apply(sapply(res.r.3, function(sub) sub[[k]]$I.z), 1, mean)
    I.z.30.s <- apply(sapply(res.r.3, function(sub) sub[[k]]$I.z), 1, sd)
    
    tmp.3[[k]] <- data.frame(RsqAdj.30.3.m=RsqAdj.30.m, RsqAdj.30.3.s=RsqAdj.30.s, 
                           RsqAdjPos.30.3.m=RsqAdjPos.30.m, RsqAdjPos.30.3.s=RsqAdjPos.30.s, 
                           Morans.I.30.3.m=Morans.I.30.m, Morans.I.30.3.s=Morans.I.30.s,
                           C.30.3.m=C.30.m, C.30.3.s=C.30.s, 
                           Rho.30.3.m=Rho.30.m, Rho.30.3.s=Rho.30.s,
                           I.scaled.30.3.m=I.scaled.30.m, I.scaled.30.3.s=I.scaled.30.s,
                           I.scaled2.30.3.m=I.scaled2.30.m, I.scaled2.30.3.s=I.scaled2.30.s,
                           I.z.30.3.m=I.z.30.m, I.z.30.3.s=I.z.30.s)
}

tmp.500 <- list()
for(k in 1:length(res.r[[1]]))
  {
    RsqAdj.30.m <- apply(sapply(res.r.500, function(sub) sub[[k]]$RsqAdj), 1, mean)
    RsqAdj.30.s <- apply(sapply(res.r.500, function(sub) sub[[k]]$RsqAdj), 1, sd)
    RsqAdjPos.30.m <- apply(sapply(res.r.500, function(sub) sub[[k]]$RsqAdjPos), 1, mean)
    RsqAdjPos.30.s <- apply(sapply(res.r.500, function(sub) sub[[k]]$RsqAdjPos), 1, sd)
    Morans.I.30.m <- apply(sapply(res.r.500, function(sub) sub[[k]]$Morans.I), 1, mean)
    Morans.I.30.s <- apply(sapply(res.r.500, function(sub) sub[[k]]$Morans.I), 1, sd)
    C.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$C), 1, mean)
    C.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$C), 1, sd)
    Rho.30.m <- apply(sapply(res.r, function(sub) sub[[k]]$Rho), 1, mean)
    Rho.30.s <- apply(sapply(res.r, function(sub) sub[[k]]$Rho), 1, sd)
    I.scaled.30.m <- apply(sapply(res.r.500, function(sub) sub[[k]]$I.scaled), 1, mean)
    I.scaled.30.s <- apply(sapply(res.r.500, function(sub) sub[[k]]$I.scaled), 1, sd)
    I.scaled2.30.m <- apply(sapply(res.r.500, function(sub) sub[[k]]$I.scaled2), 1, mean)
    I.scaled2.30.s <- apply(sapply(res.r.500, function(sub) sub[[k]]$I.scaled2), 1, sd)
    I.z.30.m <- apply(sapply(res.r.500, function(sub) sub[[k]]$I.z), 1, mean)
    I.z.30.s <- apply(sapply(res.r.500, function(sub) sub[[k]]$I.z), 1, sd)
    
    tmp.500[[k]] <- data.frame(RsqAdj.30.500.m=RsqAdj.30.m, RsqAdj.30.500.s=RsqAdj.30.s, 
                           RsqAdjPos.30.500.m=RsqAdjPos.30.m, RsqAdjPos.30.500.s=RsqAdjPos.30.s, 
                           Morans.I.30.500.m=Morans.I.30.m, Morans.I.30.500.s=Morans.I.30.s,
                           C.30.500.m=C.30.m, C.30.500.s=C.30.s, 
                           Rho.30.500.m=Rho.30.m, Rho.30.500.s=Rho.30.s,
                           I.scaled.30.500.m=I.scaled.30.m, I.scaled.30.500.s=I.scaled.30.s,
                           I.scaled2.30.500.m=I.scaled2.30.m, I.scaled2.30.500.s=I.scaled2.30.s,
                           I.z.30.500.m=I.z.30.m, I.z.30.500.s=I.z.30.s)
}

res.r.combined <- Reduce(cbind, tmp)
res.r.3.combined <- Reduce(cbind, tmp.3)
res.r.500.combined <- Reduce(cbind, tmp.500)
names(res.r.combined) <- paste(rep(names(Results.subsets[[1]][[1]]), each=ncol(tmp[[1]])), 
                             names(tmp[[1]]), sep=".")
names(res.r.3.combined) <- paste(rep(names(Results.subsets[[1]][[1]]), each=ncol(tmp[[1]])), 
                             names(tmp.3[[1]]), sep=".")
names(res.r.500.combined) <- paste(rep(names(Results.subsets[[1]][[1]]), each=ncol(tmp[[1]])), 
                             names(tmp.500[[1]]), sep=".")


Results.subsets.table <- data.frame(Results.table, res.r.combined, 
                                    res.r.3.combined, res.r.500.combined)
saveRDS(Results.subsets.table, paste0(here::here(), "/output/Results.subsets.table.rds"))
Results.subsets.table
```

Get maximum possible Moran's I for each subsample (same for all 90 datasets):

```{r}
I.max.30 <- sapply(Results.subsets, function(sub) max(sub[[1]][[1]]$Range))
I.min.30 <- sapply(Results.subsets, function(sub) min(sub[[1]][[1]]$Range))
data.frame(I.max.30, I.min.30)
```

## 5. Analyze results for n = 90

### a) Effect of Demography

```{r fig.height=5, fig.width=8}
#Results.subsets.table <- readRDS(paste0(here::here(), "/output/Results.subsets.table.rds"))

par(mfrow=c(2,4))
with(Results.subsets.table, boxplot(Fst.RsqAdjPos.90 ~ Demography,
     main="Fst.RsqAdjPos", ylim=c(0,1)))
with(Results.subsets.table, boxplot(Fst.Morans.I.90 ~ Demography,
     main="Fst.Morans.I", ylim=c(0,1)))
#with(Results.subsets.table, boxplot(Fst.I.scaled.90 ~ Demography,
#     main="Fst.I.scaled", ylim=c(-0.5,1)))
#lines(c(0,10), c(0,0), lty=2)
#with(Results.subsets.table, boxplot(Fst.I.scaled2.90 ~ Demography,
#     main="Fst.I.scaled2", ylim=c(-0.5,1)))
#lines(c(0,10), c(0,0), lty=2)
with(Results.subsets.table, boxplot(Fst.C.90 ~ Demography,
     main="Fst.C", ylim=c(0,1)))
with(Results.subsets.table, boxplot(Fst.Rho.90 ~ Demography,
     main="Fst.Rho", ylim=c(0,1)))


with(Results.subsets.table, boxplot(Dch.RsqAdjPos.90 ~ Demography,
     main="Dch.RsqAdjPos", ylim=c(0,1)))
with(Results.subsets.table, boxplot(Dch.Morans.I.90 ~ Demography,
     main="Dch.Morans.I", ylim=c(0,1)))
#with(Results.subsets.table, boxplot(Dch.I.scaled.90 ~ Demography,
#     main="Dch.I.scaled", ylim=c(-0.5,1)))
#lines(c(0,10), c(0,0), lty=2)
#with(Results.subsets.table, boxplot(Dch.I.scaled2.90 ~ Demography,
#     main="Dch.I.scaled2", ylim=c(-0.5,1)))
#lines(c(0,10), c(0,0), lty=2)
with(Results.subsets.table, boxplot(Dch.C.90 ~ Demography,
     main="Dch.C", ylim=c(0,1)))
with(Results.subsets.table, boxplot(Dch.Rho.90 ~ Demography,
     main="Dch.Rho", ylim=c(0,1)))
par(mfrow=c(1,1))
```
**Interpretation:**

- As expected, island model (IM) does not show spatial structure.
- Differences between 1R and 2R larger for Moran's I than RsqAdj.
- Note: all datasets with n = 90 have the same samplign design and thus the same maximum value for Moran's I of the genetic data, hence rescaling does not change the pattern, only the absolute values.
- Rescaling Moran's I for both min and max (I.scaled2) is not helpful.
- Same patterns for Fst and Dch.


### b) Effect of number of individuals

Drop IM

```{r fig.height=5, fig.width=8}
Results.subsets.table$NumInd <- factor(as.character(Results.subsets.table$NumInd))
a <- which(Results.subsets.table$Demography != "IM")
#a <- which(Results.subsets.table$Demography != "IM" & Results.subsets.table$NumInd == 20)

par(mfrow=c(2,4))
with(Results.subsets.table[a,], boxplot(Fst.RsqAdjPos.90 ~ NumInd,
     main="Fst.RsqAdjPos", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(Fst.Morans.I.90 ~ NumInd,
     main="Fst.Morans.I", ylim=c(0,1)))
#with(Results.subsets.table[a,], boxplot(Fst.I.scaled.90 ~ NumInd,
#     main="Fst.I.scaled", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(Fst.C.90 ~ NumInd,
     main="Fst.C", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(Fst.Rho.90 ~ NumInd,
     main="Fst.Rho", ylim=c(0,1)))

with(Results.subsets.table[a,], boxplot(Dch.RsqAdjPos.90 ~ NumInd,
     main="Dch.RsqAdjPos", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(Dch.Morans.I.90 ~ NumInd,
     main="Dch.Morans.I", ylim=c(0,1)))
#with(Results.subsets.table[a,], boxplot(Dch.I.scaled.90 ~ NumInd,
#     main="Dch.I.scaled", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(Dch.C.90 ~ NumInd,
     main="Dch.C", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(Dch.Rho.90 ~ NumInd,
     main="Dch.Rho", ylim=c(0,1)))

par(mfrow=c(1,1))
```

**Interpretation:**

- All measures are sensitive to the number of individuals sampled per population!
- Same patterns for Fst and Dch.
- Note as above: all datasets with n = 90 have the same samplign design and thus the same maximum value for Moran's I of the genetic data, hence rescaling does not change the pattern, only the absolute values.

### c) Effect of the number of loci

Drop IM

```{r fig.height=5, fig.width=8}
par(mfrow=c(2,4))
with(Results.subsets.table[a,], boxplot(list("500"=Fst.RsqAdjPos.90.500,
                                         "3300"=Fst.RsqAdj.90.3, "9900"=Fst.RsqAdj.90),
     main="Fst.RsqAdjPos, n=90", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("500"=Fst.Morans.I.90.500,
                                         "3300"=Fst.Morans.I.90.3, "9900"=Fst.Morans.I.90),
     main="Fst.Morans.I, n=90", ylim=c(0,1)))
#with(Results.subsets.table[a,], boxplot(list("500"=Fst.I.scaled.90.500,
#                                         "3300"=Fst.I.scaled.90.3, "9900"=Fst.I.scaled.90),
#     main="Fst.I.scaled, n=90", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("500"=Fst.C.90.500,
                                         "3300"=Fst.C.90.3, "9900"=Fst.C.90),
     main="Fst.C, n=90", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("500"=Fst.Rho.90.500,
                                         "3300"=Fst.Rho.90.3, "9900"=Fst.Rho.90),
     main="Fst.Rho, n=90", ylim=c(0,1)))


with(Results.subsets.table[a,], boxplot(list("500"=Fst.RsqAdjPos.30.500.m, 
                                         "3300"=Fst.RsqAdj.30.3.m, "9900"=Fst.RsqAdj.30.m),
     main="Fst.RsqAdjPos, n=30", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("500"=Fst.Morans.I.30.500.m, 
  "3300"=Fst.Morans.I.30.3.m, "9900"=Fst.Morans.I.30.m),
     main="Fst.Morans.I, n=30", ylim=c(0,1)))
#with(Results.subsets.table[a,], boxplot(list("500"=Fst.I.scaled.30.500.m, 
#                                         "3300"=Fst.I.scaled.30.3.m, "9900"=Fst.I.scaled.30.m),
#     main="Fst.I.scaled, n=30", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("500"=Fst.C.30.500.m, 
  "3300"=Fst.C.30.3.m, "9900"=Fst.C.30.m),
     main="Fst.C, n=30", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("500"=Fst.Rho.30.500.m, 
  "3300"=Fst.Rho.30.3.m, "9900"=Fst.Rho.30.m),
     main="Fst.Rho, n=30", ylim=c(0,1)))
par(mfrow=c(1,1))
```
**Interpretation:**

- No effect! Genetic resolution here depends on number of individuals, not loci??
- Double checked, will check again as this is counter intuitive.


## 6. Compare n = 30 to n = 90

### a) Fst by Demography and sample size

```{r}
par(mfcol=c(2,3))

with(Results.subsets.table, boxplot(Fst.30.m ~ Demography,
     main="Fst.30 (9900 loci)", ylim=c(0.011,0.015)))
with(Results.subsets.table, boxplot(Fst.90 ~ Demography,
     main="Fst.90 (9900 loci)", ylim=c(0.011,0.015)))

with(Results.subsets.table, boxplot(Fst.30.m.3 ~ Demography,
     main="Fst.30 (3300 loci)", ylim=c(0.011,0.015)))
with(Results.subsets.table, boxplot(Fst.90.3 ~ Demography,
     main="Fst.90 (3300 loci)", ylim=c(0.011,0.015)))

with(Results.subsets.table, boxplot(Fst.30.m.500 ~ Demography,
     main="Fst.30 (500 loci)", ylim=c(0.011,0.015)))
with(Results.subsets.table, boxplot(Fst.90.500 ~ Demography,
     main="Fst.90 (500 loci)", ylim=c(0.011,0.015)))

par(mfrow=c(1,1))
```

**Interpretation:**

- Fst robust towards number of loci or samples.
- Measures also non-spatial structure (IM model has similar Fst as 2R). In IM model, populations are differentiated but nearby populations are not more similar than distant ones.
- Why does 2R have lower Fst than 1R and IM?


## By number of individuals

```{r fig.height=9, fig.width=5}
par(mfrow=c(4,2))

with(Results.subsets.table[Results.subsets.table$Demography == "1R",], 
     boxplot(Fst.30.m ~ as.character(NumInd),
     main="Fst.30 (1R)", ylim=c(0.011,0.015)), xlab="NumInd")
with(Results.subsets.table[Results.subsets.table$Demography == "1R",], 
     boxplot(Fst.90 ~  as.character(NumInd),
     main="Fst.90 (1R)", ylim=c(0.011,0.015)), xlab="NumInd")

with(Results.subsets.table[Results.subsets.table$Demography == "2R",], 
     boxplot(Fst.30.m ~ as.character(NumInd),
     main="Fst.30 (2R)", ylim=c(0.011,0.015)), xlab="NumInd")
with(Results.subsets.table[Results.subsets.table$Demography == "2R",], 
     boxplot(Fst.90 ~ as.character(NumInd),
     main="Fst.90 (2R)", ylim=c(0.011,0.015)), xlab="NumInd")

with(Results.subsets.table[Results.subsets.table$Demography == "IBD",], 
     boxplot(Fst.30.m ~ as.character(NumInd),
     main="Fst.30 (IBD)", ylim=c(0.011,0.015)), xlab="NumInd")
with(Results.subsets.table[Results.subsets.table$Demography == "IBD",], 
     boxplot(Fst.90 ~ as.character(NumInd),
     main="Fst.90 (IBD)", ylim=c(0.011,0.015)), xlab="NumInd")

with(Results.subsets.table[Results.subsets.table$Demography == "IM",], 
     boxplot(Fst.30.m ~ as.character(NumInd),
     main="Fst.30 (IM)", ylim=c(0.011,0.015)), xlab="NumInd")
with(Results.subsets.table[Results.subsets.table$Demography == "IM",], 
     boxplot(Fst.90 ~ as.character(NumInd),
     main="Fst.90 (IM)", ylim=c(0.011,0.015)), xlab="NumInd")

par(mfrow=c(1,1))
```

### b) Compare response variables 

Drop IM

```{r fig.height=5, fig.width=8}
par(mfrow=c(2,3))
with(Results.subsets.table[a,], boxplot(list("30"=Fst.RsqAdjPos.30.m, "90"=Fst.RsqAdjPos.90),
     main="Fst.RsqAdjPos", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("30"=Fst.Morans.I.30.m, "90"=Fst.Morans.I.90),
     main="Fst.Morans.I", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("30"=Fst.I.scaled.30.m, "90"=Fst.I.scaled.90),
     main="Fst.I.scaled", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("30"=Fst.Rho.30.m, "90"=Fst.Rho.90),
     main="Fst.Rho", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("30"=Fst.C.30.m, "90"=Fst.C.90),
     main="Fst.C", ylim=c(0,1)))
#with(Results.subsets.table[a,], boxplot(list("30"=Fst.I.scaled2.30.m, "90"=Fst.I.scaled2.90),
#     main="Fst.I.scaled2", ylim=c(-0.5,1)))
with(Results.subsets.table[a,], boxplot(list("30"=Fst.I.z.30.m, "90"=Fst.I.z.90),
     main="Fst.I.z"))
par(mfrow=c(1,1))
```
**Interpretation:**

- All measures are sensitive to the number of populations sampled!
- Same patterns for Fst and Dch.
- Rescaled Moran's I more comparable than original Moran's I.


#### Account for sample size (Moran's I):

Cheng 2013: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0068336

Drop IM

```{r fig.height=3, fig.width=8}
par(mfrow=c(1,3))
with(Results.subsets.table[a,], boxplot(list("30"=Fst.Morans.I.30.m * 29/30, 
                                         "90"=Fst.Morans.I.90 *89/90),
     main="Fst.Morans.I", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("30"=Fst.I.scaled.30.m * 29/30,
                                         "90"=Fst.I.scaled.90*89/90),
     main="Fst.I.scaled", ylim=c(0,1)))
with(Results.subsets.table[a,], boxplot(list("30"=Fst.I.scaled2.30.m * 29/30,
                                         "90"=Fst.I.scaled2.90*89/90),
     main="Fst.I.scaled2", ylim=c(-0.5,1)))
lines(c(0,10), c(0,0), lty=3)
par(mfrow=c(1,1))
```
**Interpretation:**

- The correction by Cheng (2013): `I' = I * (n-1)/n)` makes the differences between sample sizes larger, not smaller.
- Same patterns for Fst and Dch.


### c) Paired t-tests  (without IM)

Paired t-tests for difference between mean of subsamples with n = 30 and corresponding datasets with n = 90 sites.

**Interpretation:**

- All differences are highly significant.

```{r}
with(Results.subsets.table[a,], t.test(Fst.RsqAdjPos.30.m, Fst.RsqAdjPos.90, paired=TRUE))

with(Results.subsets.table[a,], t.test(Fst.Morans.I.30.m, Fst.Morans.I.90, paired=TRUE))

with(Results.subsets.table[a,], t.test(Fst.C.30.m, Fst.C.90, paired=TRUE))

with(Results.subsets.table[a,], t.test(Fst.Rho.30.m, Fst.Rho.90, paired=TRUE))

with(Results.subsets.table[a,], t.test(Fst.I.scaled.30.m, Fst.I.scaled.90, paired=TRUE))

with(Results.subsets.table[a,], t.test(Fst.I.scaled2.30.m, Fst.I.scaled2.90, paired=TRUE))

with(Results.subsets.table[a,], t.test(Fst.Morans.I.30.m * 29/30, 
                                         Fst.Morans.I.90 *89/90, paired=TRUE))
with(Results.subsets.table[a,], t.test(Fst.I.scaled.30.m * 29/30,
                                         Fst.I.scaled.90*89/90, paired=TRUE))
with(Results.subsets.table[a,], t.test(Fst.I.scaled2.30.m * 29/30,
                                         Fst.I.scaled2.90*89/90, paired=TRUE))
```

### d) Effect sizes (without IM)

Cohen's d for paired t-test. This is interesting!

**Interpretation:**

- Smallest effect size for RsqAdj (when all demographic scenarios are included)

Drop IM

```{r}
with(Results.subsets.table[a,], mean(Fst.RsqAdjPos.30.m - Fst.RsqAdjPos.90)/ 
       sd(Fst.RsqAdj.30.m - Fst.RsqAdj.90))

with(Results.subsets.table[a,], mean(Fst.Morans.I.30.m - Fst.Morans.I.90)/
       sd(Fst.Morans.I.30.m - Fst.Morans.I.90)) 

with(Results.subsets.table[a,], mean(Fst.C.30.m - Fst.C.90)/ 
       sd(Fst.C.30.m - Fst.C.90))

with(Results.subsets.table[a,], mean(Fst.Rho.30.m - Fst.Rho.90)/
       sd(Fst.Rho.30.m - Fst.Rho.90)) 

with(Results.subsets.table[a,], mean(Fst.I.scaled.30.m - Fst.I.scaled.90)/
       sd(Fst.I.scaled.30.m - Fst.I.scaled.90))

with(Results.subsets.table[a,], mean(Fst.I.scaled2.30.m - Fst.I.scaled2.90)/
       sd(Fst.I.scaled2.30.m - Fst.I.scaled2.90))

with(Results.subsets.table[a,], mean(Fst.Morans.I.30.m * 29/30 - Fst.Morans.I.90 *89/90) /
       sd(Fst.Morans.I.30.m * 29/30 - Fst.Morans.I.90 *89/90))

with(Results.subsets.table[a,], mean(Fst.I.scaled.30.m * 29/30 - Fst.I.scaled.90*89/90) /
       sd(Fst.I.scaled.30.m * 29/30 - Fst.I.scaled.90*89/90))

with(Results.subsets.table[a,], mean(Fst.I.scaled2.30.m * 29/30 - Fst.I.scaled2.90*89/90) /
       sd(Fst.I.scaled2.30.m * 29/30 - Fst.I.scaled2.90*89/90))
```

HW Notes:

- Power of forward selection? No, because Moran's I also affected
- Nearest neighbor distance? No, because problem persists for quadrant subsets
- Population vs. sample? No, because difference gets larger when corrected
- Moran's I bad estimator of rho? No, because rho not  better. C is somewhat better.
- z-score for null distribution of Moran's I? No, because z scores even more different

## 7. Interaction Plots

### a) Interaction plots for Fst adjusted R^2  (n=90)

```{r fig.height=3, fig.width=8}
par(mfrow=c(1,3))
Results.subsets.table$NumInd <- factor(as.character(Results.subsets.table$NumInd))
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Fst.RsqAdjPos.90, ylim = c(0,1), type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Fst.RsqAdjPos.90.3, ylim = c(0,1), type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Fst.RsqAdjPos.90.500, ylim = c(0,1), type = "b", pch = c(19,17), fixed = TRUE)})

```

### b) Interaction plots for Dch adjusted R^2  (n=90)

```{r fig.height=3, fig.width=8}
par(mfrow=c(1,3))
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Dch.RsqAdjPos.90, ylim = c(0,1), type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Dch.RsqAdjPos.90.3, ylim = c(0,1), type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Dch.RsqAdjPos.90.500, ylim = c(0,1), type = "b", pch = c(19,17), fixed = TRUE)})

```


### c) Interaction plots for Morans.I  (n=90)

```{r fig.height=6, fig.width=8}
par(mfrow=c(2,3))
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Dch.Morans.I.90, ylim = c(0,1), type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Dch.Morans.I.90.3, ylim = c(0,1), type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Dch.Morans.I.90.500, ylim = c(0,1), type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Fst.Morans.I.90, ylim = c(0,1), type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Fst.Morans.I.90.3, ylim = c(0,1), type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Fst.Morans.I.90.500, ylim = c(0,1), type = "b", pch = c(19,17), fixed = TRUE)})

```

### d) Interaction plots for Scaled Morans.I using 2 scaling methods (n=90)

```{r fig.height=6, fig.width=8}
par(mfrow=c(4,3))
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Dch.I.scaled.90, ylim = c(0,1), type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Dch.I.scaled.90.3, ylim = c(0,1), type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Dch.I.scaled.90.500, ylim = c(0,1), type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Dch.I.scaled2.90, type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Dch.I.scaled2.90.3, type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Dch.I.scaled2.90.500, type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Fst.I.scaled.90, ylim = c(0,1), type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Fst.I.scaled.90.3, ylim = c(0,1), type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Fst.I.scaled.90.500, ylim = c(0,1), type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Fst.I.scaled2.90, type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Fst.I.scaled2.90.3, type = "b", pch = c(19,17), fixed = TRUE)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Fst.I.scaled2.90.500, type = "b", pch = c(19,17), fixed = TRUE)})

```
# we dont need this one! I

### e) Interaction plots for Fst adjusted R^2  (n=30) 

```{r fig.height=3, fig.width=8}
par(mfrow=c(1,3))
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Fst.RsqAdjPos.30.m)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Fst.RsqAdjPos.30.3.m)})
with(Results.subsets.table, {interaction.plot(Demography, NumInd, Fst.RsqAdjPos.30.500.m)})

```

# add the 90s for contrast


## 8. Missing sites

Simulations to compare results between full sample and sample with some missing sites. Two possible methods:

- Redo MEMgene (including MEM) for each dataset, based on available sites
- Keep MEM, do adj R2 based on positive MEM, which avoids overfitting

### a) Leave X sites out at a time

Run function in parallel:

```{r MEMgeneDrop}
start_time <- Sys.time()

Index.j <- 1:length(Sites.R.90)
R = 10
Results.drop <- rep( list(list()), R)

set.seed(297)
Drop <-lapply(c(1:R), function(r) sort(sample(1:90, 30)))

for(r in 1:R)
{
  cat(r)
  Results.drop[[r]] <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90,
                                                       subset=NULL, drop=Drop[[r]]),
                                mc.cores=detectCores())
  names(Results.drop[[r]]) <- Sites.R.90
}

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.drop, paste0(here::here(), "/output/Results.drop.rds"))
```

Repeat with refitting MEM

```{r MEMgeneDrop}
start_time <- Sys.time()

Index.j <- 1:length(Sites.R.90)
R = 10
Results.drop.MEM <- rep( list(list()), R)

for(r in 1:R)
{
  cat(r)
  Results.drop.MEM[[r]] <- mclapply(Index.j, function(j) getMEMgene(j, Dgen = Dgen.R.90,
                                                       subset=c(1:90)[-Drop[[r]]], drop=NULL),
                                mc.cores=detectCores())
  names(Results.drop.MEM[[r]]) <- Sites.R.90
}

end_time <- Sys.time()
end_time - start_time
cat("This job took", (end_time - start_time)/length(Index.j), "per dataset.")

saveRDS(Results.drop.MEM, paste0(here::here(), "/output/Results.drop.MEM.rds"))
```

### b) Compile results with dropped sites

Determine mean and sdev among the R = 10 replicate subsets for each dataset with 5 sites dropped

```{r}
Results.drop <- readRDS(paste0(here::here(), "/output/Results.drop.rds"))
Results.subsets.table <-  readRDS(paste0(here::here(), "/output/Results.subsets.table.rds"))
```


```{r}
res.r <- lapply(Results.drop, function(sub) 
  lapply(c(1:length(Results.drop[[1]][[1]])), function(k) getRes(sub, k)))

tmp <- list()
for(k in 1:length(res.r[[1]]))
  {
    S.tot.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$S.tot), 1, mean)
    S.tot.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$S.tot), 1, sd)
    RsqAdjPos.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdjPos), 1, mean)
    RsqAdjPos.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdjPos), 1, sd)
    Morans.I.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$Morans.I), 1, mean)
    Morans.I.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$Morans.I), 1, sd)
    C.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$C), 1, mean)
    C.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$C), 1, sd)
    Rho.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$Rho), 1, mean)
    Rho.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$Rho), 1, sd)
    I.scaled.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled), 1, mean)
    I.scaled.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled), 1, sd)
    I.scaled2.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled2), 1, mean)
    I.scaled2.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled2), 1, sd)
  
    tmp[[k]] <- data.frame(S.tot.drop.m=S.tot.drop.m, S.tot.drop.s=S.tot.drop.s,
                           RsqAdjPos.drop.m=RsqAdjPos.drop.m, RsqAdjPos.drop.s=RsqAdjPos.drop.s, 
                           Morans.I.drop.m=Morans.I.drop.m, Morans.I.drop.s=Morans.I.drop.s,
                           C.drop.m=C.drop.m, C.drop.s=C.drop.s, Rho.drop.m=Rho.drop.m, Rho.drop.s=Rho.drop.s,
                           I.scaled.drop.m=I.scaled.drop.m, I.scaled.drop.s=I.scaled.drop.s,
                           I.scaled2.drop.m=I.scaled2.drop.m, I.scaled2.drop.s=I.scaled2.drop.s)
}

res.r.combined <- Reduce(cbind, tmp)

names(res.r.combined) <- paste(rep(names(Results.drop[[1]][[1]]), each=ncol(tmp[[1]])), 
                             names(tmp[[1]]), sep=".")

Results.drop.table <- data.frame(Results.subsets.table, res.r.combined)
saveRDS(Results.drop.table, paste0(here::here(), "/output/Results.drop.table.rds"))
Results.drop.table
```

Determine mean and sdev among the R = 10 replicate subsets for each dataset with 5 sites dropped

```{r}
Results.drop.MEM <- readRDS(paste0(here::here(), "/output/Results.drop.MEM.rds"))
Results.drop.table <-  readRDS(paste0(here::here(), "/output/Results.drop.table.rds"))
```

Repeat with refitted MEM

```{r}
res.r <- lapply(Results.drop.MEM, function(sub) 
  lapply(c(1:length(Results.drop[[1]][[1]])), function(k) getRes(sub, k)))

tmp <- list()
for(k in 1:length(res.r[[1]]))
  {
    S.tot.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$S.tot), 1, mean)
    S.tot.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$S.tot), 1, sd)
    RsqAdjPos.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdjPos), 1, mean)
    RsqAdjPos.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$RsqAdjPos), 1, sd)
    Morans.I.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$Morans.I), 1, mean)
    Morans.I.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$Morans.I), 1, sd)
    C.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$C), 1, mean)
    C.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$C), 1, sd)
    Rho.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$Rho), 1, mean)
    Rho.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$Rho), 1, sd)
    I.scaled.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled), 1, mean)
    I.scaled.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled), 1, sd)
    I.scaled2.drop.m <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled2), 1, mean)
    I.scaled2.drop.s <- apply(sapply(res.r, function(sub) sub[[k]]$I.scaled2), 1, sd)
  
    tmp[[k]] <- data.frame(S.tot.drop.MEM.m=S.tot.drop.m, S.tot.drop.MEM.s=S.tot.drop.s,
                           RsqAdjPos.drop.MEM.m=RsqAdjPos.drop.m, RsqAdjPos.drop.MEM.s=RsqAdjPos.drop.s, 
                           Morans.I.drop.MEM.m=Morans.I.drop.m, Morans.I.drop.MEM.s=Morans.I.drop.s,
                           C.drop.MEM.m=C.drop.m, C.drop.MEM.s=C.drop.s, 
                           Rho.drop.MEM.m=Rho.drop.m, Rho.drop.MEM.s=Rho.drop.s,
                           I.scaled.drop.MEM.m=I.scaled.drop.m, I.scaled.drop.MEM.s=I.scaled.drop.s,
                           I.scaled2.drop.MEM.m=I.scaled2.drop.m, I.scaled2.drop.MEM.s=I.scaled2.drop.s)
}

res.r.combined <- Reduce(cbind, tmp)

names(res.r.combined) <- paste(rep(names(Results.drop[[1]][[1]]), each=ncol(tmp[[1]])), 
                             names(tmp[[1]]), sep=".")

Results.drop.MEM.table <- data.frame(Results.drop.table, res.r.combined)
saveRDS(Results.drop.MEM.table, paste0(here::here(), "/output/Results.drop.MEM.table.rds"))
Results.drop.MEM.table
```


Get maximum possible Moran's I for each subsample (same for all 90 datasets):

```{r}
I.max.drop <- sapply(Results.drop, function(sub) max(sub[[1]][[1]]$Range))
I.min.drop <- sapply(Results.drop, function(sub) min(sub[[1]][[1]]$Range))
I.max.drop.MEM <- sapply(Results.drop.MEM, function(sub) max(sub[[1]][[1]]$Range))
I.min.drop.MEM <- sapply(Results.drop.MEM, function(sub) min(sub[[1]][[1]]$Range))
data.frame(I.max.drop, I.min.drop, I.max.drop.MEM, I.min.drop.MEM)
```
```{r}
mean(I.max.drop.MEM)
mean(I.min.drop.MEM)
```

```{r}
#Results.drop.MEM.table$Fst.RsqAdjPos.drop.m/Results.drop.MEM.table$Fst.RsqAdjPos.90
#Results.drop.MEM.table$Fst.RsqAdjPos.drop.MEM.m/Results.drop.MEM.table$Fst.RsqAdjPos.90
#Results.drop.MEM.table$Fst.Morans.I.drop.m/Results.drop.MEM.table$Fst.Morans.I.90
#Results.drop.MEM.table$Fst.RsqAdjPos.drop.m/Results.drop.MEM.table$Fst.RsqAdjPos.90
#Results.drop.MEM.table$Fst.Morans.I.drop.m/Results.drop.MEM.table$Fst.Morans.I.90

par(mfrow=c(1,2))
with(Results.drop.MEM.table, boxplot(data.frame(Fst.RsqAdjPos.drop.MEM.m, Fst.RsqAdjPos.drop.m, Fst.RsqAdjPos.90),
                                     ylab="Fst.RsqAdjPos"))
with(Results.drop.MEM.table, boxplot(data.frame(Fst.Morans.I.drop.MEM.m, Fst.Morans.I.drop.m, Fst.Morans.I.90),
                                     ylab="Fst.Morans.I"))
par(mfrow=c(1,1))

#tmp <- lapply(c(1:length(Results.drop[[1]][[1]])), function(k) getRes(Results.drop[[1]], k))[[1]]
#tmp$RsqAdjPos / Results.table$Fst.RsqAdjPos.90
#tmp$Morans.I / Results.table$Fst.Morans.I.90
```

```{r}
par(mfrow=c(1,2))
with(Results.drop.MEM.table[Results.drop.MEM.table$Demography != "IM",], 
     boxplot(data.frame(Drop.MEM = Fst.RsqAdjPos.drop.MEM.m / Fst.RsqAdjPos.90, 
                        Drop = Fst.RsqAdjPos.drop.m / Fst.RsqAdjPos.90),
                        ylab="Fst.RsqAdjPos", ylim=c(0, 1)))
with(Results.drop.MEM.table[Results.drop.MEM.table$Demography != "IM",], 
     boxplot(data.frame(Drop.MEM = Fst.Morans.I.drop.MEM.m / Fst.Morans.I.90, 
                        Drop = Fst.Morans.I.drop.m / Fst.Morans.I.90),
                        ylab="Fst.Morans.I", ylim=c(0, 1)))
par(mfrow=c(1,1))
```


```{r}
par(mfrow=c(2,3))

with(Results.drop.MEM.table %>% filter(Demography == "1R"), 
     boxplot(data.frame(Drop.MEM=Fst.RsqAdjPos.drop.MEM.m / Fst.RsqAdjPos.90,
                        Drop=Fst.RsqAdjPos.drop.m / Fst.RsqAdjPos.90),
             ylab="AdjRsqPos", main="1R", ylim=c(0.5,1)))
lines(c(0,10), c(1,1), lty=2)

with(Results.drop.MEM.table %>% filter(Demography == "2R"), 
     boxplot(data.frame(Drop.MEM=Fst.RsqAdjPos.drop.MEM.m / Fst.RsqAdjPos.90,
                        Drop=Fst.RsqAdjPos.drop.m / Fst.RsqAdjPos.90),
             ylab="AdjRsqPos", main="2R", ylim=c(0.5,1)))
lines(c(0,10), c(1,1), lty=2)

with(Results.drop.MEM.table %>% filter(Demography == "IBD"), 
     boxplot(data.frame(Drop.MEM=Fst.RsqAdjPos.drop.MEM.m / Fst.RsqAdjPos.90,
                        Drop=Fst.RsqAdjPos.drop.m / Fst.RsqAdjPos.90),
             ylab="AdjRsqPos", main="IBD", ylim=c(0.5,1)))
lines(c(0,10), c(1,1), lty=2)

with(Results.drop.MEM.table %>% filter(Demography == "1R"), 
     boxplot(data.frame(Drop.MEM=Fst.Morans.I.drop.MEM.m / Fst.Morans.I.90,
                        Drop=Fst.Morans.I.drop.m / Fst.Morans.I.90),
             ylab="Morans.I", ylim=c(0.5,1)))
lines(c(0,10), c(1,1), lty=2)

with(Results.drop.MEM.table %>% filter(Demography == "2R"), 
     boxplot(data.frame(Drop.MEM=Fst.Morans.I.drop.MEM.m / Fst.Morans.I.90,
                        Drop=Fst.Morans.I.drop.m / Fst.Morans.I.90),
             ylab="Morans.I", ylim=c(0.5,1)))
lines(c(0,10), c(1,1), lty=2)

with(Results.drop.MEM.table %>% filter(Demography == "IBD"), 
     boxplot(data.frame(Drop.MEM=Fst.Morans.I.drop.MEM.m / Fst.Morans.I.90,
                        Drop=Fst.Morans.I.drop.m / Fst.Morans.I.90),
             ylab="Morans.I", ylim=c(0.5,1)))
lines(c(0,10), c(1,1), lty=2)

par(mfrow=c(1,1))
```
 Statistical tests
 
```{r}
with(Results.drop5.table %>% filter(Demography == "1R"), 
     t.test(Fst.RsqAdjPos.drop.m, Fst.RsqAdjPos.90, paired=TRUE))

with(Results.drop5.table %>% filter(Demography == "2R"), 
     t.test(Fst.RsqAdjPos.drop.m, Fst.RsqAdjPos.90, paired=TRUE))

with(Results.drop5.table %>% filter(Demography == "IBD"), 
     t.test(Fst.RsqAdjPos.drop.m, Fst.RsqAdjPos.90, paired=TRUE))

with(Results.drop5.table %>% filter(Demography == "1R"), 
     t.test(Fst.Morans.I.drop.m, Fst.Morans.I.90, paired=TRUE))

with(Results.drop5.table %>% filter(Demography == "2R"), 
     t.test(Fst.Morans.I.drop.m, Fst.Morans.I.90, paired=TRUE))

with(Results.drop5.table %>% filter(Demography == "IBD"), 
     t.test(Fst.Morans.I.drop.m, Fst.Morans.I.90, paired=TRUE))
```
 
 Effect sizes:
 
```{r}
Diff <- with(Results.drop5.table %>% filter(Demography == "1R"), 
     Fst.RsqAdjPos.drop.m - Fst.RsqAdjPos.90)
mean(Diff) / sd(Diff)

Diff <- with(Results.drop5.table %>% filter(Demography == "2R"), 
     Fst.RsqAdjPos.drop.m - Fst.RsqAdjPos.90)
mean(Diff) / sd(Diff)

Diff <- with(Results.drop5.table %>% filter(Demography == "IBD"), 
     Fst.RsqAdjPos.drop.m - Fst.RsqAdjPos.90)
mean(Diff) / sd(Diff)

Diff <- with(Results.drop5.table %>% filter(Demography == "1R"), 
     Fst.Morans.I.drop.m - Fst.Morans.I.90)
mean(Diff) / sd(Diff)

Diff <- with(Results.drop5.table %>% filter(Demography == "2R"), 
     Fst.Morans.I.drop.m - Fst.Morans.I.90)
mean(Diff) / sd(Diff)

Diff <- with(Results.drop5.table %>% filter(Demography == "IBD"), 
     Fst.Morans.I.drop.m - Fst.Morans.I.90)
mean(Diff) / sd(Diff)
```
 


```{r}
#Results.drop5.table <- readRDS(paste0(here::here(), "/output/Results.drop5.table.rds"))
```


## 9. Check for nonrandom genotypes (6 vs 20 individuals)

Look at the first 10 loci for Pop 1

```{r}
Data.R.90[[1]][1:20,1:11]
```

```{r}
Data.R.90[[2]][1:6,1:11]
```

Compare mean allele frequency across all loci among the 20 indidividuals

```{r}
par(mfrow=c(1,2))
plot(apply(Data.R.90[[1]][1:20,-1],1,mean))
plot(apply(Data.R.90[[2]][1:6,-1],1,mean))
par(mfrow=c(1,1))
```
=======

## 8. Summary Interaction Plots

### a) With n=90, #IND= 20 & the 9900 loci: Difference demographies in response variabe (Fst, adjusted R^2 and Moran's I).

```{r fig.height=2.5, fig.width=6}
par(mfcol=c(1,3), mar = c(5, 5, 3, 1))
b <- which(Results.subsets.table$NumInd == 20)
Results.subsets.table$Demography <- factor(Results.subsets.table$Demography, levels = c("IM", "IBD", "1R", "2R"))
with(Results.subsets.table[b,], boxplot(Fst.90 ~ Demography, ylim=c(0.0,0.015), ylab="Fst", cex.lab=1.5, cex.axis=1.5, cex.sub=1.5))
title("(a)", adj = 0, line =1, cex.main=2 )

with(Results.subsets.table[b,], boxplot(Fst.RsqAdj.90 ~ Demography, ylim=c(0.0,0.7), ylab=expression("Adjusted R "^2), cex.lab=1.5, cex.axis=1.5, cex.sub=1.5))
title("(b)", adj = 0, line =1, cex.main=2 )

with(Results.subsets.table[b,], boxplot(Fst.Morans.I.90 ~ Demography, ylim=c(0.0,0.7), ylab="Moran's I", cex.lab=1.5, cex.axis=1.5, cex.sub=1.5))
title("(c)", adj = 0, line =1, cex.main=2  )

```

### b) With n=90 and removing IM: Interaction between #Ind (20, 6) and # Loci (9900, 3300, 500) in response variabe (Fst, adjusted R^2, and Moran's I).


```{r fig.height=2.5, fig.width=6}
#Results.subsets.mutate <- cbind(as.character(Demography), NumPops, as.character(NumInd), Fst.90, Fst.90.3, Fst.90.500, Fst.RsqAdjPos.90, Fst.Morans.I.90, Fst.I.scaled.90, Fst.RsqAdjPos.90.3, Fst.Morans.I.90.3, Fst.I.scaled.90.3, Fst.RsqAdjPos.90.500, Fst.Morans.I.90.500, Fst.I.scaled.90.500)

Results.sub.long <- read.csv('Results.mutated.csv', header= T, sep=',')
Results.sub.long$NumLoci <- factor(Results.sub.long$NumLoci, levels = c("500", "3300", "9900"))
noIM <- which(Results.sub.long$Demography != "IM")

par(mfcol=c(1,3), mar = c(5, 5, 3, 1))
with(Results.sub.long[noIM,], {interaction.plot(NumInd, NumLoci, Fst, col=c("grey1","grey20","grey50"), ylab=" mean Fst", ylim=c(0.0,0.015), lwd= 3, cex.lab=1.5, cex.axis=1.5, cex.sub=1.5, xleg = "bottomright")})
title("(a)", adj = 0, line =1, cex.main=2 )

with(Results.sub.long[noIM,], {interaction.plot(NumInd, NumLoci, Adj.Rsqr.Pos, col=c("grey1","grey20","grey50"), ylab=expression("mean adjusted R"^2), ylim=c(0.0,0.6), lwd= 3, cex.lab=1.5, cex.axis=1.5, cex.sub=1.5, xleg = "bottomright")})
title("(b)", adj = 0, line =1, cex.main=2 )

with(Results.sub.long[noIM,], {interaction.plot(NumInd, NumLoci, Morans.I, col=c("grey1","grey20","grey50"), ylab="mean Moran's I", ylim=c(0.0,0.6), lwd= 3, cex.lab=1.5, cex.axis=1.5, cex.sub=1.5, xleg = "bottomright")})
title("(c)", adj = 0, line =1, cex.main=2 )
```


```{r fig.height=6, fig.width=6}
# 
# 3- Multipanel fig. one figure for each demography all on the same scale. boxplots (20 ind & 9900 loci)
# Respo= Adj R^2 & MI & scaled MI. (x axis = 60 refitting, missing values, 30 refitting)... show variability as proportion (divide each value by the value of the 90)

par(mfrow=c(3,3), mar = c(3, 5, 4, 1))

with(Results.drop.MEM.table %>% filter(Demography == "IBD" & NumInd == 20), 
     boxplot(data.frame(Comp.60=Fst.RsqAdjPos.drop.m / Fst.RsqAdjPos.90,
                        Meta.60=Fst.RsqAdjPos.drop.MEM.m / Fst.RsqAdjPos.90,
                        Meta.30=Fst.RsqAdjPos.30.m / Fst.RsqAdjPos.90),
             ylab=expression("Adjusted R"^2), cex.lab=1.5, cex.axis=1.5, main="IBD", cex.main= 2, ylim=c(0.0,1)))
lines(c(0,10), c(1,1), lty=2)

with(Results.drop.MEM.table %>% filter(Demography == "1R" & NumInd == 20), 
     boxplot(data.frame(Comp.60=Fst.RsqAdjPos.drop.m / Fst.RsqAdjPos.90,
                        Meta.60=Fst.RsqAdjPos.drop.MEM.m / Fst.RsqAdjPos.90,
                        Meta.30=Fst.RsqAdjPos.30.m / Fst.RsqAdjPos.90),
             ylab=expression("Adjusted R"^2), cex.lab=1.5, cex.axis=1.5, main="1R", cex.main=2,  ylim=c(0.0,1)))
lines(c(0,10), c(1,1), lty=2)

with(Results.drop.MEM.table %>% filter(Demography == "2R" & NumInd == 20), 
     boxplot(data.frame(Comp.60=Fst.RsqAdjPos.drop.m / Fst.RsqAdjPos.90,
                        Meta.60=Fst.RsqAdjPos.drop.MEM.m / Fst.RsqAdjPos.90,
                        Meta.30=Fst.RsqAdjPos.30.m / Fst.RsqAdjPos.90),
             ylab=expression("Adjusted R"^2), cex.lab=1.5, cex.axis=1.5, main="2R", cex.main=2, ylim=c(0.0,1)))
lines(c(0,10), c(1,1), lty=2)


with(Results.drop.MEM.table %>% filter(Demography == "IBD" & NumInd == 20), 
     boxplot(data.frame(Comp.60=Fst.Morans.I.drop.m / Fst.Morans.I.90,
                        Meta.60=Fst.Morans.I.drop.MEM.m / Fst.Morans.I.90,
                        Meta.30=Fst.Morans.I.30.m / Fst.Morans.I.90),
             ylab="Moran's I", cex.lab=1.5, cex.axis=1.5, ylim=c(0.0,1)))
lines(c(0,10), c(1,1), lty=2)

with(Results.drop.MEM.table %>% filter(Demography == "1R" & NumInd == 20), 
     boxplot(data.frame(Comp.60=Fst.Morans.I.drop.m / Fst.Morans.I.90,
                        Meta.60=Fst.Morans.I.drop.MEM.m / Fst.Morans.I.90,
                        Meta.30=Fst.Morans.I.30.m / Fst.Morans.I.90),
             ylab="Moran's I", cex.lab=1.5, cex.axis=1.5, ylim=c(0.0,1)))
lines(c(0,10), c(1,1), lty=2)

with(Results.drop.MEM.table %>% filter(Demography == "2R" & NumInd == 20), 
     boxplot(data.frame(Comp.60=Fst.Morans.I.drop.m / Fst.Morans.I.90,
                        Meta.60=Fst.Morans.I.drop.MEM.m / Fst.Morans.I.90,
                        Meta.30=Fst.Morans.I.30.m / Fst.Morans.I.90),
             ylab="Moran's I", cex.lab=1.5, cex.axis=1.5, ylim=c(0.0,1)))
lines(c(0,10), c(1,1), lty=2)


with(Results.drop.MEM.table %>% filter(Demography == "IBD" & NumInd == 20), 
     boxplot(data.frame(Comp.60=Fst.I.scaled.drop.m / Fst.I.scaled.90,
                        Meta.60=Fst.I.scaled.drop.MEM.m / Fst.I.scaled.90,
                        Meta.30=Fst.I.scaled.30.m / Fst.I.scaled.90),
             ylab="Scaled Moran,s I", cex.lab=1.5, cex.axis=1.5, ylim=c(0.0,1)))
lines(c(0,10), c(1,1), lty=2)

with(Results.drop.MEM.table %>% filter(Demography == "1R" & NumInd == 20), 
     boxplot(data.frame(Comp.60=Fst.I.scaled.drop.m / Fst.I.scaled.90,
                        Meta.60=Fst.I.scaled.drop.MEM.m / Fst.I.scaled.90,
                        Meta.30=Fst.I.scaled.30.m / Fst.I.scaled.90),
             ylab="Scaled Moran,s I", cex.lab=1.5, cex.axis=1.5, ylim=c(0.0,1)))
lines(c(0,10), c(1,1), lty=2)

with(Results.drop.MEM.table %>% filter(Demography == "2R" & NumInd == 20), 
     boxplot(data.frame(Comp.60=Fst.I.scaled.drop.m / Fst.I.scaled.90,
                        Meta.60=Fst.I.scaled.drop.MEM.m / Fst.I.scaled.90,
                        Meta.30=Fst.I.scaled.30.m / Fst.I.scaled.90),
             ylab="Scaled Moran,s I", cex.lab=1.5, cex.axis=1.5, ylim=c(0.0,1)))
lines(c(0,10), c(1,1), lty=2)

par(mfrow=c(1,1))

```



